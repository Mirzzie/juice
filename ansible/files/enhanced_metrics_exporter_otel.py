# #!/usr/bin/env python3
# """
# Thesis Log Telemetry Exporter
# - Connects to Docker Socket to read Juice Shop logs.
# - Regex matches Datadog IAST and Aikido RASP events in Real-Time.
# - Zero Latency. Zero External API Calls.
# """
# import time
# import json
# import os
# import docker
# import threading
# from prometheus_client import start_http_server, Gauge, Counter

# # ============= CONFIGURATION =============
# METRICS_DIR = '/opt/security-metrics/data'
# SCENARIO_FILE = os.path.join(METRICS_DIR, 'scenario_info.json')
# SEMGREP_FILE = os.path.join(METRICS_DIR, 'semgrep-results.json')
# JUICE_CONTAINER_NAME = 'juice-shop'

# # ============= METRICS =============
# SCENARIO_GAUGE = Gauge('thesis_scenario_id', 'Current Thesis Scenario (1=Baseline, 2=Detect, 3=Block)')
# SAST_GAUGE = Gauge('thesis_sast_vulns', 'SAST Vulnerabilities', ['severity'])

# # REAL-TIME LOG COUNTERS
# IAST_DETECTIONS = Counter('thesis_iast_detections_total', 'Real-time detections by Datadog IAST')
# RASP_DETECTIONS = Counter('thesis_rasp_detections_total', 'Real-time detections by Aikido RASP')
# RASP_BLOCKS = Counter('thesis_rasp_blocks_total', 'Real-time BLOCKS by Aikido RASP')

# # ============= LOGIC =============

# def update_scenario_metrics():
#     """Reads the JSON file generated by the shell script"""
#     try:
#         if os.path.exists(SCENARIO_FILE):
#             with open(SCENARIO_FILE, 'r') as f:
#                 data = json.load(f)
#                 SCENARIO_GAUGE.set(data.get('scenario_id', 0))
#     except Exception:
#         pass

# def update_sast_metrics():
#     """Reads Semgrep results once at startup"""
#     try:
#         if os.path.exists(SEMGREP_FILE):
#             with open(SEMGREP_FILE, 'r') as f:
#                 data = json.load(f)
#                 results = data.get('results', [])
#                 high, medium = 0, 0
#                 for res in results:
#                     sev = res.get('extra', {}).get('severity', 'INFO')
#                     if sev == 'ERROR': high += 1
#                     else: medium += 1
#                 SAST_GAUGE.labels(severity='HIGH').set(high)
#                 SAST_GAUGE.labels(severity='MEDIUM').set(medium)
#     except Exception:
#         pass

# def watch_docker_logs():
#     """Infinite loop that reads Juice Shop logs"""
#     client = docker.from_env()
#     print(f"üîå Connected to Docker. Waiting for container '{JUICE_CONTAINER_NAME}'...")

#     while True:
#         try:
#             container = client.containers.get(JUICE_CONTAINER_NAME)
#             print(f"‚úÖ Attached to {JUICE_CONTAINER_NAME} logs.")
            
#             # stream=True makes this a blocking loop that runs forever
#             for line in container.logs(stream=True, tail=0, follow=True):
#                 log_line = line.decode('utf-8', errors='ignore')
                
#                 # --- DATADOG IAST DETECTION LOGIC ---
#                 if "dd-trace" in log_line and "Vulnerability detected" in log_line:
#                     IAST_DETECTIONS.inc()
#                     print(f"üö® IAST HIT: {log_line[:50]}...")

#                 # --- AIKIDO RASP DETECTION LOGIC (FIXED TO MATCH 'Zen') ---
#                 # We look for 'Zen' OR 'Aikido' to be safe
#                 if "Zen" in log_line or "Aikido" in log_line or "@aikidosec" in log_line:
                    
#                     # Detection Event
#                     if "detected" in log_line:
#                         RASP_DETECTIONS.inc()
#                         print(f"üëÅÔ∏è RASP DETECT: {log_line[:50]}...")
                    
#                     # Blocking Event
#                     if "blocked" in log_line:
#                         RASP_BLOCKS.inc()
#                         print(f"üõ°Ô∏è RASP BLOCK: {log_line[:50]}...")
                            
#         except docker.errors.NotFound:
#             time.sleep(5)
#         except Exception as e:
#             print(f"‚ùå Docker error: {e}. Retrying...")
#             time.sleep(5)

# def main():
#     print("üöÄ Thesis Log Telemetry Exporter Running on :9999")
#     start_http_server(9999)
#     update_sast_metrics()
    
#     # Thread for scenario file watcher
#     t = threading.Thread(target=lambda: [update_scenario_metrics() or time.sleep(2) for _ in iter(int, 1)])
#     t.daemon = True
#     t.start()
    
#     # Main thread blocks on Docker logs
#     watch_docker_logs()

# if __name__ == '__main__':
#     main()

#!/usr/bin/env python3
# import time
# import json
# import os
# import docker
# import threading
# from prometheus_client import start_http_server, Gauge, Counter

# # CONFIGURATION
# METRICS_DIR = '/opt/security-metrics/data'
# SCENARIO_FILE = os.path.join(METRICS_DIR, 'scenario_info.json')
# JUICE_CONTAINER_NAME = 'juice-shop'

# # METRICS
# SCENARIO_GAUGE = Gauge('thesis_scenario_id', 'Current Thesis Scenario ID')
# IAST_DETECTIONS = Counter('thesis_iast_detections_total', 'Datadog IAST Findings', ['vuln_type'])
# RASP_DETECTIONS = Counter('thesis_rasp_detections_total', 'Aikido RASP Detections')
# RASP_BLOCKS = Counter('thesis_rasp_blocks_total', 'Aikido RASP Blocks')

# def update_scenario_metrics():
#     """Updates the Scenario ID based on the file written by the shell script"""
#     try:
#         if os.path.exists(SCENARIO_FILE):
#             with open(SCENARIO_FILE, 'r') as f:
#                 data = json.load(f)
#                 SCENARIO_GAUGE.set(data.get('scenario_id', 0))
#     except Exception:
#         pass

# def watch_docker_logs():
#     """Tails the Juice Shop logs and updates metrics in real-time"""
#     client = docker.from_env()
#     print(f"üîå Connecting to Docker... Waiting for {JUICE_CONTAINER_NAME}")
    
#     while True:
#         try:
#             container = client.containers.get(JUICE_CONTAINER_NAME)
#             print(f"‚úÖ Attached to {JUICE_CONTAINER_NAME} logs.")
            
#             for line in container.logs(stream=True, tail=0, follow=True):
#                 log = line.decode('utf-8', errors='ignore')
                
#                 # --- DATADOG IAST DETECTION ---
#                 if "Vulnerability detected" in log or "dd-trace" in log and "attack" in log.lower():
#                     vuln_type = "Generic"
#                     if "SQL" in log: vuln_type = "SQL Injection"
#                     elif "XSS" in log: vuln_type = "XSS"
#                     elif "Command" in log: vuln_type = "Command Injection"
#                     elif "Path" in log: vuln_type = "Path Traversal"
                    
#                     IAST_DETECTIONS.labels(vuln_type=vuln_type).inc()
#                     print(f"üö® IAST DETECTED: {vuln_type}")

#                 # --- AIKIDO RASP DETECTION ---
#                 # Matches both "Aikido" and "Zen" (the engine name)
#                 if "Zen" in log or "Aikido" in log:
#                     if "blocked" in log.lower():
#                         RASP_BLOCKS.inc()
#                         print("üõ°Ô∏è RASP BLOCK TRIGGERED")
#                     elif "detected" in log.lower():
#                         RASP_DETECTIONS.inc()
#                         print("üëÅÔ∏è RASP DETECTION TRIGGERED")
                        
#         except Exception as e:
#             print(f"‚ùå Docker Error: {e}. Retrying in 5s...")
#             time.sleep(5)

# if __name__ == '__main__':
#     print("üöÄ Thesis Metrics Exporter Running on Port 9999")
#     start_http_server(9999)
    
#     # Background thread to update Scenario ID
#     t = threading.Thread(target=lambda: [update_scenario_metrics() or time.sleep(2) for _ in iter(int, 1)])
#     t.daemon = True
#     t.start()
    
#     # Main thread blocks on log watching
#     watch_docker_logs()

#!/usr/bin/env python3
"""
Thesis Metrics Exporter: IAST vs RASP Comparative Analysis
Exports industry-standard DevSecOps metrics for comparing:
- DataDog IAST (Interactive Application Security Testing)
- Aikido Zen RASP (Runtime Application Self-Protection)
"""

import time
import json
import os
import re
import threading
import requests
from datetime import datetime, timedelta
from collections import defaultdict
import docker
from prometheus_client import start_http_server, Gauge, Counter, Info

# ================= CONFIGURATION =================
METRICS_DIR = '/opt/security-metrics/data'
SCENARIO_FILE = os.path.join(METRICS_DIR, 'scenario_info.json')
JUICE_CONTAINER_NAME = 'juice-shop'

# ================= METRICS =================
SCENARIO_GAUGE = Gauge('thesis_scenario_id', 'Current Thesis Scenario (1=IAST Only, 2=RASP Detect, 3=RASP Block)')
IAST_DETECTIONS = Counter('thesis_iast_detections_total', 'DataDog IAST detections', ['vuln_type'])
RASP_DETECTIONS = Counter('thesis_rasp_detections_total', 'Aikido RASP detections')
RASP_BLOCKS = Counter('thesis_rasp_blocks_total', 'Aikido RASP blocks')
REQUEST_LATENCY = Gauge('thesis_request_latency_ms', 'Average request latency')

# ================= LOGIC =================
def update_scenario_metrics():
    try:
        if os.path.exists(SCENARIO_FILE):
            with open(SCENARIO_FILE, 'r') as f:
                data = json.load(f)
                SCENARIO_GAUGE.set(data.get('scenario_id', 0))
    except: pass

def classify_attack_type(log_line):
    log = log_line.lower()
    if 'sql' in log or 'injection' in log: return 'SQL Injection'
    if 'xss' in log or 'script' in log: return 'XSS'
    if 'path' in log or 'traversal' in log: return 'Path Traversal'
    if 'rce' in log or 'command' in log: return 'Command Injection'
    return 'Generic Vulnerability'

def watch_docker_logs():
    client = docker.from_env()
    print(f"üîå Connected to Docker. Watching '{JUICE_CONTAINER_NAME}'")
    
    while True:
        try:
            container = client.containers.get(JUICE_CONTAINER_NAME)
            for line in container.logs(stream=True, tail=0, follow=True):
                log = line.decode('utf-8', errors='ignore').strip()
                if not log: continue
                
                # --- DATADOG IAST ---
                if "Vulnerability detected" in log or ("dd-trace" in log and "attack" in log.lower()):
                    vuln_type = classify_attack_type(log)
                    IAST_DETECTIONS.labels(vuln_type=vuln_type).inc()
                    print(f"üö® IAST DETECTED: {vuln_type}")

                # --- AIKIDO RASP ---
                if "Zen" in log or "Aikido" in log:
                    if "blocked" in log.lower():
                        RASP_BLOCKS.inc()
                        print(f"üõ°Ô∏è RASP BLOCKED")
                    elif "detected" in log.lower():
                        RASP_DETECTIONS.inc()
                        print(f"üëÅÔ∏è RASP DETECTED")
                        
                # --- LATENCY ---
                # Simple extraction of "X ms" if present in logs
                match = re.search(r'(\d+\.?\d*)\s*ms', log)
                if match:
                    try:
                        REQUEST_LATENCY.set(float(match.group(1)))
                    except: pass

        except Exception as e:
            print(f"‚ùå Docker error: {e}. Retrying in 5s...")
            time.sleep(5)

if __name__ == '__main__':
    print("üöÄ Thesis Metrics Exporter Running on :9999")
    start_http_server(9999)
    threading.Thread(target=lambda: [update_scenario_metrics() or time.sleep(2) for _ in iter(int, 1)], daemon=True).start()
    watch_docker_logs()