---
- name: Configure EC2 for Juice Shop with DevSecOps Tools + OpenTelemetry (Three-Scenario Testing)
  hosts: juiceshop
  become: true
  gather_facts: true

  vars:
    juice_shop_dir: /opt/juice-shop
    metrics_dir: /opt/security-metrics
    node_version: "22"
    prometheus_version: "2.48.0"
    otel_collector_version: "0.92.0"

  vars_files:
    - secrets.yml

  tasks:
    # =======================================================================
    # SYSTEM PREPARATION
    # =======================================================================
    - name: Update APT cache
      apt:
        update_cache: yes
        cache_valid_time: 3600

    - name: Install required system packages
      apt:
        name:
          - curl
          - wget
          - git
          - unzip
          - software-properties-common
          - apt-transport-https
          - ca-certificates
          - gnupg
          - lsb-release
          - jq
          - python3
          - python3-pip
          - python3-venv
        state: present

    # =======================================================================
    # DOCKER INSTALLATION
    # =======================================================================
    - name: Add Docker GPG key
      apt_key:
        url: https://download.docker.com/linux/ubuntu/gpg
        state: present

    - name: Add Docker repository
      apt_repository:
        repo: "deb [arch=amd64] https://download.docker.com/linux/ubuntu {{ ansible_distribution_release }} stable"
        state: present

    - name: Install Docker
      apt:
        name:
          - docker-ce
          - docker-ce-cli
          - containerd.io
          - docker-buildx-plugin
          - docker-compose-plugin
        state: present
        update_cache: yes

    - name: Add ubuntu user to docker group
      user:
        name: ubuntu
        groups: docker
        append: yes

    - name: Start and enable Docker service
      systemd:
        name: docker
        state: started
        enabled: yes

    # =======================================================================
    # OPENTELEMETRY COLLECTOR INSTALLATION
    # =======================================================================
    - name: Create OpenTelemetry Collector directory
      file:
        path: /opt/otel-collector
        state: directory
        mode: '0755'

    - name: Download OpenTelemetry Collector
      get_url:
        url: "https://github.com/open-telemetry/opentelemetry-collector-releases/releases/download/v{{ otel_collector_version }}/otelcol-contrib_{{ otel_collector_version }}_linux_amd64.tar.gz"
        dest: /tmp/otelcol.tar.gz
        mode: '0644'

    - name: Extract OpenTelemetry Collector
      unarchive:
        src: /tmp/otelcol.tar.gz
        dest: /opt/otel-collector
        remote_src: yes
        creates: /opt/otel-collector/otelcol-contrib

    - name: Create OpenTelemetry Collector configuration
      copy:
        dest: /opt/otel-collector/config.yaml
        content: |
          # OpenTelemetry Collector Configuration for IAST/RASP Metrics Collection
          
          receivers:
            # OTLP Receiver for DataDog and Aikido
            otlp:
              protocols:
                grpc:
                  endpoint: 0.0.0.0:4317
                http:
                  endpoint: 0.0.0.0:4318
            
            # Prometheus receiver for self-monitoring
            prometheus:
              config:
                scrape_configs:
                  - job_name: 'otel-collector'
                    scrape_interval: 30s
                    static_configs:
                      - targets: ['localhost:8888']

          processors:
            # Batch processor for efficiency
            batch:
              timeout: 10s
              send_batch_size: 1024
            
            # Add resource attributes
            resource:
              attributes:
                - key: deployment.environment
                  value: dev
                  action: upsert
                - key: service.namespace
                  value: juice-shop-devsecops
                  action: upsert
            
            # Memory limiter to prevent OOM
            memory_limiter:
              check_interval: 1s
              limit_mib: 512
              spike_limit_mib: 128
            
            # Attributes processor for enrichment
            attributes:
              actions:
                - key: collector.name
                  value: "security-metrics-otel"
                  action: insert

          exporters:
            # Prometheus Remote Write (for local Prometheus)
            prometheusremotewrite:
              endpoint: "http://localhost:9090/api/v1/write"
              tls:
                insecure: true
            
            # Prometheus exporter (exposes metrics on :8889)
            prometheus:
              endpoint: "0.0.0.0:8889"
              namespace: "otel"
              const_labels:
                environment: dev
            
            # Logging exporter for debugging
            logging:
              loglevel: info
              sampling_initial: 5
              sampling_thereafter: 200
            
            # OTLP exporter (forward to DataDog if needed)
            otlp/datadog:
              endpoint: "https://trace.agent.{{ datadog_site }}:443"
              headers:
                DD-API-KEY: "{{ datadog_api_key }}"
              tls:
                insecure: false

          service:
            pipelines:
              # Traces pipeline
              traces:
                receivers: [otlp]
                processors: [memory_limiter, resource, attributes, batch]
                exporters: [logging, otlp/datadog]
              
              # Metrics pipeline
              metrics:
                receivers: [otlp, prometheus]
                processors: [memory_limiter, resource, attributes, batch]
                exporters: [prometheus, prometheusremotewrite, logging]
              
              # Logs pipeline
              logs:
                receivers: [otlp]
                processors: [memory_limiter, resource, attributes, batch]
                exporters: [logging, otlp/datadog]
            
            # Telemetry configuration
            telemetry:
              logs:
                level: info
              metrics:
                address: 0.0.0.0:8888
        mode: '0644'

    - name: Create OpenTelemetry Collector systemd service
      copy:
        dest: /etc/systemd/system/otel-collector.service
        content: |
          [Unit]
          Description=OpenTelemetry Collector for Security Metrics
          After=network.target

          [Service]
          Type=simple
          User=root
          ExecStart=/opt/otel-collector/otelcol-contrib --config=/opt/otel-collector/config.yaml
          Restart=always
          RestartSec=10
          StandardOutput=journal
          StandardError=journal

          [Install]
          WantedBy=multi-user.target
        mode: '0644'

    - name: Enable and start OpenTelemetry Collector
      systemd:
        name: otel-collector
        enabled: yes
        state: started
        daemon_reload: yes

    # =======================================================================
    # DATADOG AGENT INSTALLATION
    # =======================================================================
    - name: Check if DataDog agent is already installed
      stat:
        path: /etc/datadog-agent
      register: datadog_installed

    - name: Download DataDog installation script
      get_url:
        url: "https://install.datadoghq.com/scripts/install_script_agent7.sh"
        dest: /tmp/install_datadog.sh
        mode: '0755'
      when: not datadog_installed.stat.exists

    - name: Install DataDog Agent
      shell: >
        DD_API_KEY={{ datadog_api_key }} DD_SITE={{ datadog_site }} bash /tmp/install_datadog.sh
      args:
        creates: /etc/datadog-agent/datadog.yaml
      when: not datadog_installed.stat.exists
      register: datadog_install
      retries: 3
      delay: 15
      until: datadog_install.rc == 0

    - name: Configure DataDog Agent for APM, IAST, and OpenTelemetry
      blockinfile:
        path: /etc/datadog-agent/datadog.yaml
        block: |
          # APM Configuration
          apm_config:
            enabled: true
            apm_non_local_traffic: true
            receiver_port: 8126
            receiver_timeout: 10
            max_traces_per_second: 100
            
            # OpenTelemetry Configuration
            otlp_config:
              receiver:
                protocols:
                  grpc:
                    endpoint: 0.0.0.0:4317
                  http:
                    endpoint: 0.0.0.0:4318
              traces:
                enabled: true
              metrics:
                enabled: true
              logs:
                enabled: true

          # AppSec & IAST Configuration
          appsec_config:
            enabled: true

          runtime_security_config:
            enabled: true

          # Process Monitoring
          process_config:
            enabled: "true"
            scrub_args: true

          # Log Collection
          logs_enabled: true
          logs_config:
            container_collect_all: true
            
          # OpenTelemetry Metrics Export
          otlp_config:
            metrics:
              enabled: true
            traces:
              enabled: true
            logs:
              enabled: true
        marker: "# {mark} ANSIBLE MANAGED BLOCK - DEVSECOPS + OTEL CONFIG"
        create: no
        backup: yes
      notify: Restart DataDog Agent

    - name: Ensure DataDog Agent is running
      systemd:
        name: datadog-agent
        state: started
        enabled: yes

    # =======================================================================
    # PROMETHEUS INSTALLATION
    # =======================================================================
    - name: Create Prometheus user
      user:
        name: prometheus
        system: yes
        shell: /bin/false
        create_home: no

    - name: Create Prometheus directories
      file:
        path: "{{ item }}"
        state: directory
        owner: prometheus
        group: prometheus
        mode: '0755'
      loop:
        - /etc/prometheus
        - /var/lib/prometheus

    - name: Download and extract Prometheus
      unarchive:
        src: "https://github.com/prometheus/prometheus/releases/download/v{{ prometheus_version }}/prometheus-{{ prometheus_version }}.linux-amd64.tar.gz"
        dest: /tmp
        remote_src: yes
        creates: /tmp/prometheus-{{ prometheus_version }}.linux-amd64

    - name: Copy Prometheus binaries
      copy:
        src: "/tmp/prometheus-{{ prometheus_version }}.linux-amd64/{{ item }}"
        dest: /usr/local/bin/
        mode: '0755'
        owner: prometheus
        group: prometheus
        remote_src: yes
      loop:
        - prometheus
        - promtool

    - name: Create Prometheus configuration with OpenTelemetry and three-scenario support
      copy:
        dest: /etc/prometheus/prometheus.yml
        content: |
          global:
            scrape_interval: 15s
            evaluation_interval: 15s
            external_labels:
              cluster: 'devsecops-thesis'
              environment: 'dev'

          # Remote write configuration (receives from OTel Collector)
          remote_write:
            - url: http://localhost:9090/api/v1/write

          scrape_configs:
            # Prometheus self-monitoring
            - job_name: 'prometheus'
              static_configs:
                - targets: ['localhost:9090']

            # Security Metrics Exporter (main custom exporter)
            - job_name: 'security-metrics-exporter'
              static_configs:
                - targets: ['localhost:9999']
              scrape_interval: 30s
              metric_relabel_configs:
                - source_labels: [scenario]
                  target_label: test_scenario
                  action: replace

            # OpenTelemetry Collector metrics
            - job_name: 'otel-collector'
              static_configs:
                - targets: ['localhost:8888']
              scrape_interval: 30s

            # OpenTelemetry Collector Prometheus exporter
            - job_name: 'otel-prometheus-exporter'
              static_configs:
                - targets: ['localhost:8889']
              scrape_interval: 30s
              metric_relabel_configs:
                - source_labels: [__name__]
                  regex: 'otel_.*'
                  action: keep

            # DataDog Agent metrics (if exposed)
            - job_name: 'datadog-agent'
              static_configs:
                - targets: ['localhost:5000']
              scrape_interval: 30s
              metrics_path: /metrics
              scheme: http
        owner: prometheus
        group: prometheus
        mode: '0644'
      notify: Restart Prometheus

    - name: Create Prometheus systemd service
      copy:
        dest: /etc/systemd/system/prometheus.service
        content: |
          [Unit]
          Description=Prometheus
          Wants=network-online.target
          After=network-online.target

          [Service]
          User=prometheus
          Group=prometheus
          Type=simple
          ExecStart=/usr/local/bin/prometheus \
            --config.file=/etc/prometheus/prometheus.yml \
            --storage.tsdb.path=/var/lib/prometheus/ \
            --web.console.templates=/etc/prometheus/consoles \
            --web.console.libraries=/etc/prometheus/console_libraries \
            --web.enable-remote-write-receiver \
            --web.enable-lifecycle

          [Install]
          WantedBy=multi-user.target
        mode: '0644'
      notify: Restart Prometheus

    - name: Enable and start Prometheus
      systemd:
        name: prometheus
        enabled: yes
        state: started
        daemon_reload: yes

    # =======================================================================
    # GRAFANA INSTALLATION
    # =======================================================================
    - name: Add Grafana GPG key
      apt_key:
        url: https://apt.grafana.com/gpg.key
        state: present

    - name: Add Grafana repository
      apt_repository:
        repo: "deb https://apt.grafana.com stable main"
        state: present

    - name: Install Grafana
      apt:
        name: grafana
        state: present
        update_cache: yes

    - name: Configure Grafana to run on port 3001
      lineinfile:
        path: /etc/grafana/grafana.ini
        regexp: '^;?http_port ='
        line: 'http_port = 3001'
        state: present
      notify: Restart Grafana

    - name: Create Grafana provisioning directories
      file:
        path: "/etc/grafana/provisioning/{{ item }}"
        state: directory
        owner: grafana
        group: grafana
        mode: '0755'
      loop:
        - datasources
        - dashboards

    - name: Configure Prometheus datasource for Grafana
      copy:
        dest: /etc/grafana/provisioning/datasources/prometheus.yml
        content: |
          apiVersion: 1
          datasources:
            - name: Prometheus
              type: prometheus
              access: proxy
              url: http://localhost:9090
              isDefault: true
              editable: false
              jsonData:
                timeInterval: "15s"
        owner: grafana
        group: grafana
        mode: '0644'
      notify: Restart Grafana

    - name: Create dashboard provisioning config
      copy:
        dest: /etc/grafana/provisioning/dashboards/default.yml
        content: |
          apiVersion: 1
          providers:
            - name: 'Default'
              orgId: 1
              folder: ''
              type: file
              disableDeletion: false
              updateIntervalSeconds: 10
              allowUiUpdates: true
              options:
                path: /var/lib/grafana/dashboards
        owner: grafana
        group: grafana
        mode: '0644'
      notify: Restart Grafana

    - name: Create Grafana dashboards directory
      file:
        path: /var/lib/grafana/dashboards
        state: directory
        owner: grafana
        group: grafana
        mode: '0755'

    - name: Copy Three-Scenario Comparison Dashboard
      copy:
        src: files/grafana-three-scenario-dashboard.json
        dest: /var/lib/grafana/dashboards/three-scenario-comparison.json
        owner: grafana
        group: grafana
        mode: '0644'
      notify: Restart Grafana

    - name: Enable and start Grafana
      systemd:
        name: grafana-server
        enabled: yes
        state: started

    # =======================================================================
    # ENHANCED METRICS EXPORTER SETUP (OpenTelemetry-Aware)
    # =======================================================================
    - name: Create metrics directory structure
      file:
        path: "{{ item }}"
        state: directory
        owner: ubuntu
        group: ubuntu
        mode: '0755'
      loop:
        - "{{ metrics_dir }}"
        - "{{ metrics_dir }}/zap-results"
        - "{{ metrics_dir }}/data"

    - name: Create Python virtual environment for metrics exporter
      command: python3 -m venv {{ metrics_dir }}/venv
      args:
        creates: "{{ metrics_dir }}/venv"
      become_user: ubuntu

    - name: Install Python dependencies for metrics exporter (with OpenTelemetry support)
      pip:
        name:
          - prometheus_client
          - requests
          - flask
          - opentelemetry-api
          - opentelemetry-sdk
          - opentelemetry-exporter-otlp
          - opentelemetry-instrumentation
        virtualenv: "{{ metrics_dir }}/venv"
      become_user: ubuntu

    - name: Copy Enhanced OpenTelemetry-Aware Metrics Exporter
      copy:
        src: files/enhanced_metrics_exporter_otel.py
        dest: "{{ metrics_dir }}/metrics_exporter.py"
        owner: ubuntu
        group: ubuntu
        mode: '0755'

    - name: Create metrics exporter systemd service (with OTel support)
      copy:
        dest: /etc/systemd/system/security-metrics-exporter.service
        content: |
          [Unit]
          Description=Security Metrics Exporter for Prometheus (SAST/DAST/IAST/RASP + OpenTelemetry)
          After=network.target prometheus.service otel-collector.service

          [Service]
          Type=simple
          User=ubuntu
          WorkingDirectory={{ metrics_dir }}
          Environment="DD_API_KEY={{ datadog_api_key }}"
          Environment="DD_APP_KEY={{ datadog_app_key }}"
          Environment="DD_SITE={{ datadog_site }}"
          Environment="AIKIDO_TOKEN={{ aikido_token }}"
          Environment="OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4317"
          Environment="OTEL_SERVICE_NAME=security-metrics-exporter"
          ExecStart={{ metrics_dir }}/venv/bin/python {{ metrics_dir }}/metrics_exporter.py
          Restart=always
          RestartSec=10
          StandardOutput=journal
          StandardError=journal

          [Install]
          WantedBy=multi-user.target
        mode: '0644'
      notify: Restart Metrics Exporter

    - name: Enable and start metrics exporter
      systemd:
        name: security-metrics-exporter
        enabled: yes
        state: started
        daemon_reload: yes

    - name: Initialize scenario tracking file
      copy:
        dest: "{{ metrics_dir }}/data/scenario_info.json"
        content: |
          {
            "current_scenario": "unknown",
            "scenario_id": 0,
            "scenario_name": "Not Started",
            "rasp_enabled": false,
            "rasp_blocking": false,
            "timestamp": "{{ ansible_date_time.iso8601 }}"
          }
        owner: ubuntu
        group: ubuntu
        mode: '0644'
        force: no

    - name: Initialize manual metrics file
      copy:
        dest: "{{ metrics_dir }}/data/manual_metrics.json"
        content: |
          {
            "scan_phase": 0,
            "scenario": "unknown",
            "scenario_id": 0,
            "response_times": {
              "datadog_iast": 0,
              "aikido_rasp": 0
            }
          }
        owner: ubuntu
        group: ubuntu
        mode: '0644'
        force: no

    # =======================================================================
    # APPLICATION SETUP (WITH OPENTELEMETRY)
    # =======================================================================
    - name: Create application directory
      file:
        path: "{{ juice_shop_dir }}"
        state: directory
        owner: ubuntu
        group: ubuntu
        mode: '0755'

    - name: Clone Juice Shop repository
      git:
        repo: https://github.com/juice-shop/juice-shop.git
        dest: "{{ juice_shop_dir }}"
        depth: 1
        update: yes
        force: yes
      become: true
      become_user: ubuntu

    - name: Ensure repo ownership is ubuntu
      file:
        path: "{{ juice_shop_dir }}"
        owner: ubuntu
        group: ubuntu
        recurse: yes

    - name: Create tracer.ts (DataDog + OpenTelemetry)
      copy:
        dest: "{{ juice_shop_dir }}/tracer.ts"
        content: |
          // tracer.ts - DataDog APM with OpenTelemetry support
          import tracer from 'dd-trace';
          
          tracer.init({
            logInjection: true,
            runtimeMetrics: true,
            appsec: true,
            iast: true,
            // OpenTelemetry export configuration
            experimental: {
              exporter: 'otlp',
              enableGetRUMData: true
            }
          });
          
          export default tracer;
        owner: ubuntu
        group: ubuntu
        mode: '0644'

    - name: Create Dockerfile (OpenTelemetry-enabled)
      copy:
        dest: "{{ juice_shop_dir }}/Dockerfile"
        content: |
          # Multi-stage Dockerfile for Juice Shop with Security Tools + OpenTelemetry
          FROM node:22-bookworm-slim AS builder

          RUN apt-get update && apt-get install -y git python3 make g++ && rm -rf /var/lib/apt/lists/*
          WORKDIR /juice-shop

          # Clone Juice Shop
          RUN git clone --depth 1 https://github.com/juice-shop/juice-shop.git . && rm -rf .git

          # Install ALL dependencies
          RUN npm install

          # Install security tools with OpenTelemetry support
          RUN npm install --save-exact \
              @aikidosec/firewall \
              dd-trace \
              @opentelemetry/api \
              @opentelemetry/sdk-node \
              @opentelemetry/auto-instrumentations-node \
              @opentelemetry/exporter-trace-otlp-grpc \
              @opentelemetry/exporter-metrics-otlp-grpc

          # Copy tracer
          COPY tracer.ts ./tracer.ts

          # Modify TypeScript source files BEFORE compilation
          RUN sed -i "1i import './tracer' // DataDog APM + OTEL" app.ts && \
              sed -i "2i import '@aikidosec/firewall' // Aikido RASP" app.ts && \
              sed -i "1i import './tracer' // DataDog APM + OTEL" server.ts && \
              sed -i "2i import '@aikidosec/firewall' // Aikido RASP" server.ts

          # Verify modifications
          RUN echo "=== Modified app.ts ===" && head -10 app.ts && \
              echo "=== Modified server.ts ===" && head -10 server.ts

          # Compile TypeScript
          RUN npx tsc || npm run build:server || echo "TypeScript compilation attempted"
          
          # Verify compilation
          RUN ls -la build/ && \
              echo "=== build/app.js (first 30 lines) ===" && \
              head -30 build/app.js

          # Build frontend
          RUN cd frontend && npm install --legacy-peer-deps && \
              node ./node_modules/@angular/cli/bin/ng build --configuration production || echo "Frontend build completed"

          # --- Production stage ---
          FROM node:22-bookworm-slim
          
          RUN apt-get update && apt-get install -y curl procps && rm -rf /var/lib/apt/lists/*
          RUN groupadd -r juiceshop && useradd -r -g juiceshop juiceshop
          
          WORKDIR /juice-shop

          # Copy entire application
          COPY --from=builder --chown=juiceshop:juiceshop /juice-shop /juice-shop

          # Ensure directories exist
          RUN mkdir -p /juice-shop/logs /juice-shop/ftp /juice-shop/data && \
              chown -R juiceshop:juiceshop /juice-shop

          USER juiceshop
          EXPOSE 3000

          HEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=3 \
            CMD curl -f http://localhost:3000/rest/admin/application-version || exit 1

          ENV NODE_ENV=production \
              PORT=3000 \
              NODE_OPTIONS="--max-old-space-size=2048 --require ./build/tracer.js"
          
          CMD ["npm", "start"]
        owner: ubuntu
        group: ubuntu
        mode: '0644'

    - name: Create base docker-compose.yml template
      copy:
        dest: "{{ juice_shop_dir }}/docker-compose.yml"
        content: |
          services:
            juice-shop:
              build: .
              image: juice-shop-secure:latest
              container_name: juice-shop
              restart: unless-stopped
              ports:
                - "3000:3000"
              environment:
                NODE_ENV: production
                
                # DataDog Configuration (will be modified per scenario)
                DD_ENV: dev
                DD_SERVICE: juice-shop
                DD_VERSION: latest
                DD_AGENT_HOST: 172.17.0.1
                DD_TRACE_AGENT_PORT: 8126
                DD_LOGS_INJECTION: "true"
                DD_TRACE_SAMPLE_RATE: "1"
                DD_APPSEC_ENABLED: "true"
                DD_IAST_ENABLED: "true"
                
                # Aikido Configuration (will be modified per scenario)
                AIKIDO_TOKEN: ${AIKIDO_TOKEN}
                AIKIDO_BLOCK: "false"
                AIKIDO_DEBUG: "true"
                
              env_file:
                - .env
              extra_hosts:
                - "host.docker.internal:host-gateway"
              healthcheck:
                test: ["CMD", "curl", "-f", "http://localhost:3000"]
                interval: 30s
                timeout: 10s
                retries: 3
                start_period: 60s
        owner: ubuntu
        group: ubuntu
        mode: '0644'

    - name: Create .env file with secrets
      copy:
        dest: "{{ juice_shop_dir }}/.env"
        content: |
          # Aikido Zen RASP Configuration
          AIKIDO_TOKEN={{ aikido_token }}
          AIKIDO_BLOCK=false
          AIKIDO_DEBUG=true
          
          # DataDog Configuration
          DD_ENV=dev
          DD_VERSION=latest
          
          # OpenTelemetry Configuration
          OTEL_EXPORTER_OTLP_ENDPOINT=http://172.17.0.1:4317
          OTEL_SERVICE_NAME=juice-shop
        owner: ubuntu
        group: ubuntu
        mode: '0600'
      no_log: true

    # =======================================================================
    # POST-INSTALLATION VERIFICATION
    # =======================================================================
    - name: Wait for services to stabilize
      pause:
        seconds: 15

    - name: Verify all services are running
      shell: |
        echo "=== Service Status Check ==="
        systemctl is-active prometheus && echo "‚úÖ Prometheus: Active" || echo "‚ùå Prometheus: Inactive"
        systemctl is-active grafana-server && echo "‚úÖ Grafana: Active" || echo "‚ùå Grafana: Inactive"
        systemctl is-active otel-collector && echo "‚úÖ OpenTelemetry Collector: Active" || echo "‚ùå OTel Collector: Inactive"
        systemctl is-active security-metrics-exporter && echo "‚úÖ Metrics Exporter: Active" || echo "‚ùå Metrics Exporter: Inactive"
        systemctl is-active datadog-agent && echo "‚úÖ DataDog Agent: Active" || echo "‚ùå DataDog Agent: Inactive"
      register: service_check
      changed_when: false

    - name: Display service status
      debug:
        msg: "{{ service_check.stdout_lines }}"

    - name: Display setup completion summary
      debug:
        msg:
          - "============================================================================"
          - "‚úÖ THREE-SCENARIO TESTING INFRASTRUCTURE WITH OPENTELEMETRY - READY"
          - "============================================================================"
          - ""
          - "üìä Monitoring Stack:"
          - "  - Prometheus: http://{{ ansible_host }}:9090 (with remote-write enabled)"
          - "  - Grafana: http://{{ ansible_host }}:3001 (admin/admin)"
          - "  - Metrics Exporter: http://{{ ansible_host }}:9999/metrics"
          - "  - OpenTelemetry Collector: http://{{ ansible_host }}:4317 (gRPC)"
          - "  - OpenTelemetry Metrics: http://{{ ansible_host }}:8889/metrics"
          - ""
          - "üîí Security Tools:"
          - "  - DataDog Agent: Active (APM + IAST + OTLP receiver)"
          - "  - Aikido RASP: Ready (scenario-dependent, with metrics export)"
          - "  - OpenTelemetry Collector: Receiving from both DataDog & Aikido"
          - ""
          - "üì° OpenTelemetry Data Flow:"
          - "  DataDog IAST ‚Üí OTLP ‚Üí OTel Collector ‚Üí Prometheus ‚Üí Grafana"
          - "  Aikido RASP ‚Üí OTLP ‚Üí OTel Collector ‚Üí Prometheus ‚Üí Grafana"
          - ""
          - "üéØ Three-Scenario Testing Capability:"
          - "  - Scenario 1: IAST Only (no RASP) ‚Üí Baseline detection"
          - "  - Scenario 2A: IAST + RASP (detection-only) ‚Üí Enhanced detection"
          - "  - Scenario 2B: IAST + RASP (blocking mode) ‚Üí Active protection"
          - ""
          - "üìà Grafana Dashboards:"
          - "  - Three-Scenario Comparison: Side-by-side analysis"
          - "  - OpenTelemetry Metrics: Full observability"
          - "  - Detection vs Blocking: Key thesis validation"
          - ""
          - "üöÄ Next Steps:"
          - "  1. Run GitHub Actions pipeline (will execute all 3 scenarios)"
          - "  2. View real-time metrics in Grafana"
          - "  3. Analyze OpenTelemetry traces in DataDog"
          - "  4. Export data for thesis statistical analysis"
          - ""
          - "üìä Key Metrics Available:"
          - "  - security_detections_total{scenario=...} ‚Üí All detections"
          - "  - security_blocks_total{scenario='iast-rasp-block'} ‚Üí RASP blocks"
          - "  - otel_* ‚Üí OpenTelemetry collector metrics"
          - "  - dast_vulnerabilities_found{scenario=...} ‚Üí DAST findings"
          - ""
          - "üéì Thesis Validation:"
          - "  Compare blocking rates: Scenario 2B should show ~80% blocks"
          - "  while Scenarios 1 and 2A show 0% blocks, proving RASP superiority"
          - "============================================================================"

  handlers:
    - name: Restart DataDog Agent
      systemd:
        name: datadog-agent
        state: restarted

    - name: Restart Prometheus
      systemd:
        name: prometheus
        state: restarted

    - name: Restart Grafana
      systemd:
        name: grafana-server
        state: restarted

    - name: Restart Metrics Exporter
      systemd:
        name: security-metrics-exporter
        state: restarted

    - name: Restart OpenTelemetry Collector
      systemd:
        name: otel-collector
        state: restarted