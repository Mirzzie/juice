name: IAST vs RASP Security Comparison Pipeline

on:
  push:
    branches: [main, dev-test]
  pull_request:
    branches: [main, dev-test]
  workflow_dispatch:
    inputs:
      skip_ansible:
        description: "Skip Ansible deployment"
        required: false
        type: boolean
        default: false
      attack_rounds:
        description: "Number of attack rounds per configuration"
        required: false
        type: number
        default: 3
      deploy_continuous:
        description: "Deploy 24/7 continuous benchmark system"
        required: false
        type: boolean
        default: false

env:
  EC2_INSTANCE_IP: ${{ secrets.EC2_INSTANCE_IP }}
  SEMGREP_APP_TOKEN: ${{ secrets.SEMGREP_APP_TOKEN }}
  EC2_SSH_PRIVATE_KEY: ${{ secrets.EC2_SSH_PRIVATE_KEY }}
  ANSIBLE_VAULT_PASSWORD: ${{ secrets.ANSIBLE_VAULT_PASSWORD }}
  AIKIDO_TOKEN: ${{ secrets.ZEN_FIREWALL_TOKEN }}

jobs:
  # ============================================================================
  # SAST: Static Analysis (Code Quality Check)
  # ============================================================================
  sast-semgrep:
    name: ğŸ” SAST - Semgrep Security Scan
    runs-on: ubuntu-latest
    container:
      image: semgrep/semgrep
    steps:
      - name: Checkout Code
        uses: actions/checkout@v4

      - name: Run Semgrep SAST Scan
        run: |
          semgrep scan --config=auto --json --output=semgrep-results.json || true
          semgrep scan --config=auto --sarif --output=semgrep-results.sarif || true
        env:
          SEMGREP_APP_TOKEN: ${{ secrets.SEMGREP_APP_TOKEN }}

      - name: Upload to Semgrep Dashboard
        if: always()
        run: semgrep ci
        env:
          SEMGREP_APP_TOKEN: ${{ secrets.SEMGREP_APP_TOKEN }}
        continue-on-error: true

      - name: Upload SARIF to GitHub Security
        if: always()
        uses: github/codeql-action/upload-sarif@v3
        with:
          sarif_file: semgrep-results.sarif
          category: semgrep
        continue-on-error: true

      - name: Upload SAST Results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: sast-results
          path: |
            semgrep-results.json
            semgrep-results.sarif

  # ============================================================================
  # Prerequisites Check
  # ============================================================================
  check-prerequisites:
    name: âœ… Verify Prerequisites
    runs-on: ubuntu-latest
    needs: sast-semgrep
    outputs:
      can_proceed: ${{ steps.check.outputs.can_proceed }}
    steps:
      - name: Check Required Secrets
        id: check
        run: |
          echo "Checking required secrets..."
          MISSING=()
          [ -z "${{ secrets.EC2_INSTANCE_IP }}" ] && MISSING+=("EC2_INSTANCE_IP")
          [ -z "${{ secrets.EC2_SSH_PRIVATE_KEY }}" ] && MISSING+=("EC2_SSH_PRIVATE_KEY")
          [ -z "${{ secrets.ANSIBLE_VAULT_PASSWORD }}" ] && MISSING+=("ANSIBLE_VAULT_PASSWORD")
          [ -z "${{ secrets.ZEN_FIREWALL_TOKEN }}" ] && MISSING+=("ZEN_FIREWALL_TOKEN")

          if [ ${#MISSING[@]} -ne 0 ]; then
            echo "::error::Missing secrets: ${MISSING[*]}"
            echo "can_proceed=false" >> $GITHUB_OUTPUT
            exit 1
          fi

          echo "âœ… All required secrets are configured"
          echo "can_proceed=true" >> $GITHUB_OUTPUT

  # ============================================================================
  # Deploy Infrastructure
  # ============================================================================
  configure-instance:
    name: âš™ï¸ Configure EC2 Instance
    runs-on: ubuntu-latest
    needs: check-prerequisites
    if: |
      needs.check-prerequisites.outputs.can_proceed == 'true' &&
      github.event.inputs.skip_ansible != 'true'
    steps:
      - name: Checkout Code
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install Ansible
        run: pip install ansible boto3

      - name: Setup SSH
        run: |
          mkdir -p ~/.ssh
          echo "${{ secrets.EC2_SSH_PRIVATE_KEY }}" > ~/.ssh/id_rsa
          chmod 600 ~/.ssh/id_rsa
          cat >> ~/.ssh/config << 'EOF'
          Host *
            ServerAliveInterval 30
            ServerAliveCountMax 10
            TCPKeepAlive yes
          EOF

      - name: Wait for SSH
        run: |
          for i in {1..30}; do
            if ssh -o StrictHostKeyChecking=no -o ConnectTimeout=5 \
               -i ~/.ssh/id_rsa ubuntu@${{ env.EC2_INSTANCE_IP }} \
               "echo 'SSH ready'" 2>/dev/null; then
              echo "âœ… SSH connection established"
              exit 0
            fi
            echo "Waiting for SSH... ($i/30)"
            sleep 10
          done
          echo "::error::SSH timeout"
          exit 1

      - name: Create Ansible Inventory
        run: |
          mkdir -p ansible
          cat > ansible/inventory.ini <<EOF
          [juiceshop]
          ${{ env.EC2_INSTANCE_IP }} ansible_user=ubuntu ansible_ssh_private_key_file=~/.ssh/id_rsa ansible_ssh_common_args='-o StrictHostKeyChecking=no'
          EOF

      - name: Create Vault Password File
        run: |
          cd ansible
          echo "${{ secrets.ANSIBLE_VAULT_PASSWORD }}" > .vault_pass
          chmod 600 .vault_pass

      - name: Run Ansible Playbook
        run: |
          cd ansible
          ansible-playbook -i inventory.ini playbook.yml \
            --vault-password-file .vault_pass -v
        timeout-minutes: 60

      - name: Clean Up
        if: always()
        run: rm -f ansible/.vault_pass

  # ============================================================================
  # Deploy Continuous Benchmark (24/7 Testing)
  # ============================================================================
  deploy-continuous-benchmark:
    name: ğŸ”„ Deploy Continuous Benchmark System
    runs-on: ubuntu-latest
    needs: [check-prerequisites, configure-instance]
    if: |
      needs.check-prerequisites.outputs.can_proceed == 'true' &&
      (needs.configure-instance.result == 'success' || needs.configure-instance.result == 'skipped') &&
      (github.ref == 'refs/heads/main' || github.event.inputs.deploy_continuous == 'true')
    steps:
      - name: Setup SSH
        run: |
          mkdir -p ~/.ssh
          echo "${{ secrets.EC2_SSH_PRIVATE_KEY }}" > ~/.ssh/id_rsa
          chmod 600 ~/.ssh/id_rsa
          ssh-keyscan -H ${{ env.EC2_INSTANCE_IP }} >> ~/.ssh/known_hosts

      - name: Verify System Configuration
        run: |
          ssh -i ~/.ssh/id_rsa ubuntu@${{ env.EC2_INSTANCE_IP }} \
            'test -f /opt/benchmark-tools/start_iast_rasp_system.sh && echo "âœ… System configured"'

      - name: Launch Continuous System
        run: |
          ssh -i ~/.ssh/id_rsa ubuntu@${{ env.EC2_INSTANCE_IP }} \
            'cd /opt/benchmark-tools && nohup ./start_iast_rasp_system.sh > /tmp/system_startup.log 2>&1 &'
          echo "âœ… Continuous benchmark system launched"

      - name: Wait for Initialization
        run: sleep 45

      - name: Check System Status
        run: |
          ssh -i ~/.ssh/id_rsa ubuntu@${{ env.EC2_INSTANCE_IP }} << 'EOF'
            echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
            echo "System Status"
            echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
            systemctl is-active iast-rasp-benchmark && echo "âœ… Benchmark Service: ACTIVE" || echo "â³ Starting..."
            docker ps | grep -q prometheus && echo "âœ… Prometheus: UP" || echo "â³ Starting..."
            docker ps | grep -q grafana && echo "âœ… Grafana: UP" || echo "â³ Starting..."
            pgrep -f prometheus_exporter.py > /dev/null && echo "âœ… Metrics Exporter: UP" || echo "â³ Starting..."
          EOF
        continue-on-error: true

      - name: Create Deployment Summary
        if: always()
        run: |
          cat >> $GITHUB_STEP_SUMMARY << EOF
          # ğŸ¯ IAST vs RASP Continuous Benchmark Deployed

          ## ğŸ“Š Access Dashboards

          | Service | URL | Credentials |
          |---------|-----|-------------|
          | **Grafana** | [http://${{ env.EC2_INSTANCE_IP }}:3001](http://${{ env.EC2_INSTANCE_IP }}:3001) | admin / iast_rasp_2024 |
          | **Prometheus** | [http://${{ env.EC2_INSTANCE_IP }}:9090](http://${{ env.EC2_INSTANCE_IP }}:9090) | None |
          | **Metrics** | [http://${{ env.EC2_INSTANCE_IP }}:8000/metrics](http://${{ env.EC2_INSTANCE_IP }}:8000/metrics) | None |

          ## ğŸ”„ How It Works

          1. **Configuration Rotation**: System alternates between IAST and RASP every 60 minutes
          2. **DAST Attacks**: Automated attacks run every 5 minutes
          3. **Real-time Metrics**: All data flows to Prometheus â†’ Grafana
          4. **Continuous Collection**: 24/7 automated testing

          ## ğŸ“ˆ What You'll See in Grafana

          - **Blocking Effectiveness**: IAST (detection only) vs RASP (detection + blocking)
          - **Detection Rates**: Real-time detection percentages
          - **RASP Advantage**: Calculated superiority percentage
          - **Attack Breakdown**: SQLi, XSS, Path Traversal results

          ## ğŸ”§ Management Commands

          \`\`\`bash
          # Check system status
          ssh ubuntu@${{ env.EC2_INSTANCE_IP }} systemctl status iast-rasp-benchmark

          # View logs
          ssh ubuntu@${{ env.EC2_INSTANCE_IP }} journalctl -u iast-rasp-benchmark -f

          # View startup log
          ssh ubuntu@${{ env.EC2_INSTANCE_IP }} tail -50 /tmp/system_startup.log
          \`\`\`

          â° **Status**: System is initializing. Dashboards ready in 5-10 minutes.
          EOF

  # ============================================================================
  # Manual Test Runs (IAST vs RASP Comparison)
  # ============================================================================
  iast-vs-rasp-comparison:
    name: ğŸ§ª ${{ matrix.config_display }}
    runs-on: ubuntu-latest
    needs: [check-prerequisites, configure-instance]
    if: |
      needs.check-prerequisites.outputs.can_proceed == 'true' &&
      (needs.configure-instance.result == 'success' || needs.configure-instance.result == 'skipped') &&
      github.event.inputs.deploy_continuous != 'true'
    strategy:
      max-parallel: 1
      fail-fast: false
      matrix:
        include:
          - config: iast-detection
            config_display: "DataDog IAST (Detection Only)"
            dd_appsec: "true"
            dd_iast: "true"
            aikido_block: "false"
            security_tool: "IAST"
          - config: rasp-protection
            config_display: "Aikido RASP (Detection + Blocking)"
            dd_appsec: "false"
            dd_iast: "false"
            aikido_block: "true"
            security_tool: "RASP"

    steps:
      - name: Checkout Code
        uses: actions/checkout@v4

      - name: Setup SSH
        run: |
          mkdir -p ~/.ssh
          echo "${{ secrets.EC2_SSH_PRIVATE_KEY }}" > ~/.ssh/id_rsa
          chmod 600 ~/.ssh/id_rsa
          ssh-keyscan -H ${{ env.EC2_INSTANCE_IP }} >> ~/.ssh/known_hosts

      - name: Deploy ${{ matrix.config_display }} Configuration
        run: |
          ssh -i ~/.ssh/id_rsa ubuntu@${{ env.EC2_INSTANCE_IP }} << 'ENDSSH'
            set -e
            cd /opt/juice-shop

            echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
            echo "ğŸ”§ Deploying: ${{ matrix.config_display }}"
            echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"

            # Update environment
            cat > .env << 'EOF'
          SECURITY_MODE=${{ matrix.config }}
          DD_APPSEC_ENABLED=${{ matrix.dd_appsec }}
          DD_IAST_ENABLED=${{ matrix.dd_iast }}
          AIKIDO_BLOCK=${{ matrix.aikido_block }}
          AIKIDO_TOKEN=${{ secrets.ZEN_FIREWALL_TOKEN }}
          EOF

            # Restart application
            docker compose down 2>/dev/null || true
            sleep 5
            docker compose up -d

            # Wait for application
            echo "â³ Waiting for application..."
            for i in {1..20}; do
              if curl -f -s http://localhost:3000 > /dev/null 2>&1; then
                echo "âœ… Application is ready"
                echo ""
                echo "Configuration Active:"
                echo "  Tool: ${{ matrix.security_tool }}"
                echo "  IAST Enabled: ${{ matrix.dd_iast }}"
                echo "  RASP Blocking: ${{ matrix.aikido_block }}"
                exit 0
              fi
              sleep 3
            done

            echo "âš ï¸  Application delayed, continuing..."
          ENDSSH
        timeout-minutes: 5

      - name: Run DAST Attack Suite (Round ${{ matrix.round }})
        run: |
          ROUNDS=${{ github.event.inputs.attack_rounds || 3 }}

          for ROUND in $(seq 1 $ROUNDS); do
            echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
            echo "ğŸ¯ DAST Attack Round $ROUND/$ROUNDS"
            echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
            
            ssh -i ~/.ssh/id_rsa ubuntu@${{ env.EC2_INSTANCE_IP }} << 'ENDSSH'
              RESULTS_DIR="/tmp/benchmark-results/${{ matrix.config }}/round_${ROUND}"
              mkdir -p "$RESULTS_DIR"
              
              # Run all DAST attacks
              /opt/benchmark-tools/run_all_attacks.sh \
                "http://localhost:3000" \
                "${{ matrix.config }}" \
                "$RESULTS_DIR"
              
              # Extract security events from logs
              docker logs juice-shop > "$RESULTS_DIR/container.log" 2>&1 || true
              
              grep -i "aikido\|datadog\|blocked\|detected\|vulnerability" \
                "$RESULTS_DIR/container.log" > "$RESULTS_DIR/security_events.log" 2>&1 || true
              
              BLOCKED=$(grep -ci "blocked" "$RESULTS_DIR/security_events.log" 2>/dev/null || echo "0")
              DETECTED=$(grep -ci "detected\|vulnerability" "$RESULTS_DIR/security_events.log" 2>/dev/null || echo "0")
              
              echo "METRIC,COUNT" > "$RESULTS_DIR/security_events.csv"
              echo "BLOCKED,$BLOCKED" >> "$RESULTS_DIR/security_events.csv"
              echo "DETECTED,$DETECTED" >> "$RESULTS_DIR/security_events.csv"
              
              echo "ğŸ“Š Security Events: $DETECTED detected, $BLOCKED blocked"
          ENDSSH
            
            # Wait between rounds
            [ $ROUND -lt $ROUNDS ] && sleep 30
          done
        timeout-minutes: 15

      - name: Download Results
        run: |
          mkdir -p ./results/${{ matrix.config }}
          scp -i ~/.ssh/id_rsa -r \
            ubuntu@${{ env.EC2_INSTANCE_IP }}:/tmp/benchmark-results/${{ matrix.config }}/* \
            ./results/${{ matrix.config }}/ 2>/dev/null || echo "âš ï¸  Partial results"
        timeout-minutes: 3

      - name: Upload Results Artifact
        uses: actions/upload-artifact@v4
        with:
          name: results-${{ matrix.config }}
          path: ./results/${{ matrix.config }}/
          retention-days: 30

  # ============================================================================
  # Comparative Analysis & Report
  # ============================================================================
  comparative-analysis:
    name: ğŸ“Š Generate IAST vs RASP Comparison Report
    runs-on: ubuntu-latest
    needs: iast-vs-rasp-comparison
    if: always() && needs.iast-vs-rasp-comparison.result != 'skipped'
    steps:
      - name: Checkout Code
        uses: actions/checkout@v4

      - name: Download All Results
        uses: actions/download-artifact@v4
        with:
          path: ./all-results
        continue-on-error: true

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install Analysis Tools
        run: pip install pandas tabulate

      - name: Generate Comparative Analysis
        run: |
          python3 << 'PYEOF'
          import pandas as pd
          from pathlib import Path
          import json

          results_dir = Path('./all-results')

          if not results_dir.exists():
              print("âš ï¸  No results found")
              with open('comparison_report.csv', 'w') as f:
                  f.write('Config,Status\n')
                  f.write('ALL,NO_RESULTS\n')
              exit(0)

          all_data = []

          for config in ['iast-detection', 'rasp-protection']:
              config_dir = results_dir / f'results-{config}' / config
              if not config_dir.exists():
                  continue
              
              # Process all rounds
              for round_dir in config_dir.glob('round_*'):
                  summary_file = round_dir / 'summary.csv'
                  if summary_file.exists():
                      try:
                          df = pd.read_csv(summary_file)
                          for _, row in df.iterrows():
                              if 'ATTACK_TYPE' in row and row.get('ATTACK_TYPE') != 'DURATION_SECONDS':
                                  total = int(row.get('TOTAL', 0))
                                  detected = int(row.get('DETECTED', 0))
                                  blocked = int(row.get('BLOCKED', 0))
                                  
                                  all_data.append({
                                      'Configuration': config,
                                      'Tool': 'IAST' if config == 'iast-detection' else 'RASP',
                                      'Attack_Type': row.get('ATTACK_TYPE', 'UNKNOWN'),
                                      'Total': total,
                                      'Detected': detected,
                                      'Blocked': blocked,
                                      'Detection_Rate': f"{((detected + blocked) / max(total, 1)) * 100:.1f}%",
                                      'Blocking_Rate': f"{(blocked / max(total, 1)) * 100:.1f}%"
                                  })
                      except Exception as e:
                          print(f"Error processing {summary_file}: {e}")

          if not all_data:
              print("âš ï¸  No data collected")
              with open('comparison_report.csv', 'w') as f:
                  f.write('Config,Status\n')
                  f.write('ALL,NO_DATA\n')
          else:
              df = pd.DataFrame(all_data)
              df.to_csv('detailed_results.csv', index=False)
              
              # Create summary comparison
              summary = []
              for config in ['iast-detection', 'rasp-protection']:
                  config_data = df[df['Configuration'] == config]
                  if len(config_data) > 0:
                      total = config_data['Total'].sum()
                      detected = config_data['Detected'].sum()
                      blocked = config_data['Blocked'].sum()
                      
                      summary.append({
                          'Tool': config_data['Tool'].iloc[0],
                          'Configuration': config,
                          'Total_Attacks': int(total),
                          'Detected': int(detected),
                          'Blocked': int(blocked),
                          'Detection_Rate': f"{((detected + blocked) / total * 100):.1f}%" if total > 0 else "N/A",
                          'Blocking_Rate': f"{(blocked / total * 100):.1f}%" if total > 0 else "N/A"
                      })
              
              pd.DataFrame(summary).to_csv('comparison_report.csv', index=False)
              print("âœ… Analysis complete")
          PYEOF

      - name: Generate Comprehensive Report
        run: |
          cat > COMPARISON_REPORT.md << 'EOF'
          # ğŸ”’ IAST vs RASP Security Comparison Report

          **Pipeline Run:** #${{ github.run_number }}  
          **Date:** $(date '+%Y-%m-%d %H:%M:%S UTC')  
          **Branch:** ${{ github.ref_name }}

          ## ğŸ“‹ Testing Methodology

          ### Security Tools Tested
          1. **DataDog IAST** (Interactive Application Security Testing)
             - Runtime detection from inside the application
             - Passive monitoring only (no blocking)
             - Reports vulnerabilities to DataDog dashboard

          2. **Aikido Zen RASP** (Runtime Application Self-Protection)
             - Runtime detection + active blocking
             - Protects application in real-time
             - Blocks malicious requests automatically

          ### Attack Approach (DAST)
          - **Dynamic Application Security Testing** using custom attack scripts
          - Attack types: SQL Injection, XSS, Path Traversal
          - Same attacks sent to both configurations for fair comparison

          EOF

          if [ -f comparison_report.csv ] && [ $(wc -l < comparison_report.csv) -gt 1 ]; then
            python3 << 'PYEOF' >> COMPARISON_REPORT.md || echo "_Analysis unavailable_" >> COMPARISON_REPORT.md
          import pandas as pd
          try:
              df = pd.read_csv('comparison_report.csv')
              if len(df) > 0:
                  print("\n## ğŸ“Š Results Summary\n")
                  print(df.to_markdown(index=False))
                  
                  # Calculate advantage
                  iast = df[df['Tool'] == 'IAST']
                  rasp = df[df['Tool'] == 'RASP']
                  
                  if len(iast) > 0 and len(rasp) > 0:
                      rasp_block = float(rasp['Blocking_Rate'].values[0].strip('%'))
                      iast_block = float(iast['Blocking_Rate'].values[0].strip('%'))
                      
                      rasp_detect = float(rasp['Detection_Rate'].values[0].strip('%'))
                      iast_detect = float(iast['Detection_Rate'].values[0].strip('%'))
                      
                      print(f"\n## ğŸ† Key Findings\n")
                      print(f"### Blocking Capability")
                      print(f"- **RASP**: {rasp_block:.1f}% of attacks blocked")
                      print(f"- **IAST**: {iast_block:.1f}% of attacks blocked")
                      print(f"- **Advantage**: RASP blocks {rasp_block - iast_block:.1f}% more attacks\n")
                      
                      print(f"### Detection Capability")
                      print(f"- **RASP**: {rasp_detect:.1f}% detection rate")
                      print(f"- **IAST**: {iast_detect:.1f}% detection rate")
                      print(f"- **Advantage**: RASP detects {rasp_detect - iast_detect:.1f}% more attacks\n")
                      
                      print(f"### Conclusion")
                      print(f"**Aikido Zen RASP demonstrates superior protection** with both detection and active blocking capabilities, while DataDog IAST provides detection-only monitoring.")
          except Exception as e:
              print(f"Error: {e}")
          PYEOF
          else
            echo "âš ï¸  No benchmark data available" >> COMPARISON_REPORT.md
          fi

          cat >> COMPARISON_REPORT.md << 'EOF'

          ## ğŸ”„ Continuous Monitoring

          For real-time, continuous monitoring:
          - Deploy the continuous benchmark system
          - View live metrics in Grafana
          - Track performance over days/weeks
          - Generate statistically significant comparisons

          EOF

          cat COMPARISON_REPORT.md >> $GITHUB_STEP_SUMMARY

      - name: Upload Comparison Report
        uses: actions/upload-artifact@v4
        with:
          name: iast-vs-rasp-comparison-report
          path: |
            COMPARISON_REPORT.md
            comparison_report.csv
            detailed_results.csv
          retention-days: 90
