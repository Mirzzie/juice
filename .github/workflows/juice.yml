name: RASP vs IAST Comparative Benchmarking Pipeline

on:
  push:
    branches: [main, dev, dev-test]
  pull_request:
    branches: [main, dev, dev-test]
  workflow_dispatch:
    inputs:
      skip_ansible:
        description: "Skip Ansible configuration"
        required: false
        type: boolean
        default: true
      test_configurations:
        description: "Test configurations to run"
        required: false
        type: choice
        default: "all"
        options:
          - all
          - baseline
          - iast-only
          - rasp-monitor
          - rasp-block
      run_full_security_scan:
        description: "Run full DAST scan"
        required: false
        type: boolean
        default: true

env:
  EC2_INSTANCE_IP: ${{ secrets.EC2_INSTANCE_IP }}
  SEMGREP_APP_TOKEN: ${{ secrets.SEMGREP_APP_TOKEN }}
  EC2_SSH_PRIVATE_KEY: ${{ secrets.EC2_SSH_PRIVATE_KEY }}
  ANSIBLE_VAULT_PASSWORD: ${{ secrets.ANSIBLE_VAULT_PASSWORD }}

jobs:
  sast-semgrep:
    name: üîç SAST - Semgrep Security Scan
    runs-on: ubuntu-latest
    container:
      image: semgrep/semgrep
    steps:
      - name: Checkout Code
        uses: actions/checkout@v4

      - name: Run Semgrep Scan
        run: |
          semgrep scan --config=auto --json --output=semgrep-results.json || true
          semgrep scan --config=auto --sarif --output=semgrep-results.sarif || true
        env:
          SEMGREP_APP_TOKEN: ${{ secrets.SEMGREP_APP_TOKEN }}

      - name: Upload to Semgrep Dashboard
        if: always()
        run: semgrep ci
        env:
          SEMGREP_APP_TOKEN: ${{ secrets.SEMGREP_APP_TOKEN }}
        continue-on-error: true

      - name: Upload SARIF to GitHub Security
        if: always()
        uses: github/codeql-action/upload-sarif@v3
        with:
          sarif_file: semgrep-results.sarif
          category: semgrep
        continue-on-error: true

      - name: Upload Semgrep Artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: semgrep-results
          path: |
            semgrep-results.json
            semgrep-results.sarif

  check-prerequisites:
    name: ‚úÖ Verify Prerequisites
    runs-on: ubuntu-latest
    needs: sast-semgrep
    outputs:
      can_proceed: ${{ steps.check.outputs.can_proceed }}
    steps:
      - name: Check Required Secrets
        id: check
        run: |
          echo "Checking required secrets..."
          MISSING_SECRETS=()
          if [ -z "${{ secrets.EC2_INSTANCE_IP }}" ]; then
            MISSING_SECRETS+=("EC2_INSTANCE_IP")
          fi
          if [ -z "${{ secrets.EC2_SSH_PRIVATE_KEY }}" ]; then
            MISSING_SECRETS+=("EC2_SSH_PRIVATE_KEY")
          fi
          if [ -z "${{ secrets.ANSIBLE_VAULT_PASSWORD }}" ]; then
            MISSING_SECRETS+=("ANSIBLE_VAULT_PASSWORD")
          fi
          if [ ${#MISSING_SECRETS[@]} -ne 0 ]; then
            echo "::error::Missing required secrets: ${MISSING_SECRETS[*]}"
            echo "can_proceed=false" >> $GITHUB_OUTPUT
            exit 1
          fi
          echo "‚úÖ All required secrets are set"
          echo "can_proceed=true" >> $GITHUB_OUTPUT

  configure-instance:
    name: ‚öôÔ∏è Configure Instance with Ansible
    runs-on: ubuntu-latest
    needs: check-prerequisites
    if: |
      needs.check-prerequisites.outputs.can_proceed == 'true' &&
      (github.event.inputs.skip_ansible == 'false' || github.event.inputs.skip_ansible == '')
    steps:
      - name: Checkout Code
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install Ansible
        run: pip install ansible boto3 botocore

      - name: Setup SSH Key
        run: |
          mkdir -p ~/.ssh
          echo "${{ secrets.EC2_SSH_PRIVATE_KEY }}" > ~/.ssh/id_rsa
          chmod 600 ~/.ssh/id_rsa

      - name: Wait for SSH Availability
        run: |
          echo "Testing SSH connection..."
          for i in {1..30}; do
            if ssh -o StrictHostKeyChecking=no -o ConnectTimeout=5 \
               -i ~/.ssh/id_rsa ubuntu@${{ env.EC2_INSTANCE_IP }} \
               "echo 'SSH ready'" 2>/dev/null; then
              echo "‚úÖ SSH connection successful"
              exit 0
            fi
            echo "Attempt $i/30: Waiting for SSH..."
            sleep 10
          done
          echo "::error::SSH connection timeout"
          exit 1

      - name: Create Ansible Inventory
        run: |
          mkdir -p ansible
          cat > ansible/inventory.ini <<EOF
          [juiceshop]
          ${{ env.EC2_INSTANCE_IP }} ansible_user=ubuntu ansible_ssh_private_key_file=~/.ssh/id_rsa ansible_ssh_common_args='-o StrictHostKeyChecking=no'
          EOF

      - name: Create Vault Password File
        run: |
          cd ansible
          echo "${{ secrets.ANSIBLE_VAULT_PASSWORD }}" > .vault_pass
          chmod 600 .vault_pass

      - name: Run Ansible Playbook
        run: |
          cd ansible
          ansible-playbook -i inventory.ini playbook.yml \
            --vault-password-file .vault_pass -v

      - name: Clean Up Vault Password
        if: always()
        run: rm -f ansible/.vault_pass

  setup-benchmarking:
    name: üõ†Ô∏è Verify Attack Tools
    runs-on: ubuntu-latest
    needs: [check-prerequisites, configure-instance]
    if: |
      always() &&
      needs.check-prerequisites.outputs.can_proceed == 'true' &&
      (needs.configure-instance.result == 'success' || needs.configure-instance.result == 'skipped')
    steps:
      - name: Setup SSH Key
        run: |
          mkdir -p ~/.ssh
          echo "${{ secrets.EC2_SSH_PRIVATE_KEY }}" > ~/.ssh/id_rsa
          chmod 600 ~/.ssh/id_rsa
          ssh-keyscan -H ${{ env.EC2_INSTANCE_IP }} >> ~/.ssh/known_hosts

      - name: Verify Attack Tools Installation
        run: |
          ssh -T -i ~/.ssh/id_rsa ubuntu@${{ env.EC2_INSTANCE_IP }} << 'ENDSSH'
            echo "üì¶ Verifying attack automation tools..."
            
            # Check if scripts exist
            if [ -d "/opt/benchmark-tools" ]; then
              echo "‚úÖ Benchmark tools directory exists"
              ls -la /opt/benchmark-tools/
            else
              echo "‚ö†Ô∏è  Benchmark tools not found - run with skip_ansible: false"
            fi
            
            # Verify SQLmap
            if command -v sqlmap &> /dev/null; then
              echo "‚úÖ SQLmap installed: $(sqlmap --version 2>&1 | head -1)"
            else
              echo "‚ö†Ô∏è  SQLmap not found"
            fi
            
            # Verify Python packages
            echo "‚úÖ Checking Python packages..."
            python3 -c "import requests; print('‚úÖ requests OK')" || echo "‚ö†Ô∏è  requests missing"
            python3 -c "import bs4; print('‚úÖ beautifulsoup4 OK')" || echo "‚ö†Ô∏è  bs4 missing"
            
            echo "‚úÖ Verification complete"
          ENDSSH

  benchmark-tests:
    name: üß™ ${{ matrix.config_name }}
    runs-on: ubuntu-latest
    needs: [check-prerequisites, setup-benchmarking]
    if: |
      always() &&
      needs.check-prerequisites.outputs.can_proceed == 'true' &&
      needs.setup-benchmarking.result == 'success'
    strategy:
      max-parallel: 1
      fail-fast: false
      matrix:
        include:
          - config: baseline
            config_name: "Configuration 1: Baseline (No Protection)"
            dd_appsec: "false"
            dd_iast: "false"
            aikido_block: "false"
            aikido_enabled: "false"
          - config: iast-only
            config_name: "Configuration 2: DataDog IAST Only"
            dd_appsec: "true"
            dd_iast: "true"
            aikido_block: "false"
            aikido_enabled: "false"
          - config: rasp-monitor
            config_name: "Configuration 3: Zen RASP (Monitoring)"
            dd_appsec: "false"
            dd_iast: "false"
            aikido_block: "false"
            aikido_enabled: "true"
          - config: rasp-block
            config_name: "Configuration 4: Zen RASP (Blocking)"
            dd_appsec: "false"
            dd_iast: "false"
            aikido_block: "true"
            aikido_enabled: "true"

    steps:
      - name: Checkout Code
        uses: actions/checkout@v4

      - name: Setup SSH Key
        run: |
          mkdir -p ~/.ssh
          echo "${{ secrets.EC2_SSH_PRIVATE_KEY }}" > ~/.ssh/id_rsa
          chmod 600 ~/.ssh/id_rsa
          ssh-keyscan -H ${{ env.EC2_INSTANCE_IP }} >> ~/.ssh/known_hosts

          # Configure SSH for long-running operations
          cat >> ~/.ssh/config << 'SSHEOF'
          Host *
            ServerAliveInterval 60
            ServerAliveCountMax 30
            TCPKeepAlive yes
          SSHEOF

      - name: Deploy Application with ${{ matrix.config }} Configuration
        run: |
          # Create deployment script
          cat > /tmp/deploy.sh << 'DEPLOYEOF'
          set -e
          cd /opt/juice-shop

          echo "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê"
          echo "üöÄ Deploying: ${{ matrix.config_name }}"
          echo "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê"

          # Stop existing containers
          docker compose down 2>/dev/null || true

          # Update environment configuration
          cat > .env << ENVEOF
          AIKIDO_TOKEN=${{ secrets.ZEN_FIREWALL_TOKEN }}
          AIKIDO_BLOCK=${{ matrix.aikido_block }}
          AIKIDO_DEBUG=true
          DD_ENV=${{ matrix.config }}
          DD_VERSION=latest
          ENVEOF

          # Update docker-compose.yml
          cat > docker-compose.yml << COMPOSEEOF
          services:
            juice-shop:
              build: .
              image: juice-shop-secure:latest
              container_name: juice-shop
              restart: unless-stopped
              ports:
                - "3000:3000"
              environment:
                NODE_ENV: production
                DD_ENV: ${{ matrix.config }}
                DD_SERVICE: juice-shop
                DD_VERSION: latest
                DD_AGENT_HOST: 172.17.0.1
                DD_TRACE_AGENT_PORT: 8126
                DD_LOGS_INJECTION: "true"
                DD_TRACE_SAMPLE_RATE: "1"
                DD_PROFILING_ENABLED: "true"
                DD_RUNTIME_METRICS_ENABLED: "true"
                DD_APPSEC_ENABLED: "${{ matrix.dd_appsec }}"
                DD_IAST_ENABLED: "${{ matrix.dd_iast }}"
                AIKIDO_TOKEN: \${AIKIDO_TOKEN}
                AIKIDO_BLOCK: "${{ matrix.aikido_block }}"
                AIKIDO_DEBUG: "true"
                AIKIDO_ENABLED: "${{ matrix.aikido_enabled }}"
              env_file:
                - .env
              extra_hosts:
                - "host.docker.internal:host-gateway"
              healthcheck:
                test: ["CMD", "curl", "-f", "http://localhost:3000"]
                interval: 30s
                timeout: 10s
                retries: 3
                start_period: 60s
          COMPOSEEOF

          # Build image only if doesn't exist
          if ! docker images | grep -q "juice-shop-secure.*latest"; then
            echo "üì¶ Building Docker image (first time - this takes ~15 minutes)..."
            nohup docker compose build --no-cache > /tmp/build.log 2>&1 &
            BUILD_PID=$!
            
            # Wait with keep-alive messages
            while kill -0 $BUILD_PID 2>/dev/null; do
              echo "Building... ($(date '+%H:%M:%S'))"
              sleep 30
            done
            
            wait $BUILD_PID
            BUILD_EXIT=$?
            if [ $BUILD_EXIT -ne 0 ]; then
              echo "‚ùå Build failed with exit code $BUILD_EXIT"
              tail -100 /tmp/build.log
              exit 1
            fi
            echo "‚úÖ Build completed"
          else
            echo "‚úÖ Using existing image"
          fi

          echo "‚ñ∂Ô∏è  Starting container..."
          docker compose up -d

          echo "‚è≥ Waiting for application..."
          sleep 60

          # Verify
          if ! docker ps | grep -q juice-shop; then
            echo "‚ùå Container failed to start"
            docker compose logs --tail=50
            exit 1
          fi

          for i in {1..10}; do
            if curl -f -s http://localhost:3000 > /dev/null; then
              echo "‚úÖ Application ready"
              echo ""
              echo "üìã Configuration:"
              echo "  - DataDog AppSec: ${{ matrix.dd_appsec }}"
              echo "  - DataDog IAST: ${{ matrix.dd_iast }}"
              echo "  - Aikido Enabled: ${{ matrix.aikido_enabled }}"
              echo "  - Aikido Blocking: ${{ matrix.aikido_block }}"
              exit 0
            fi
            echo "Waiting... ($i/10)"
            sleep 5
          done

          echo "‚ö†Ô∏è  Application may need more time"
          exit 0
          DEPLOYEOF

          # Copy and execute script
          scp -i ~/.ssh/id_rsa /tmp/deploy.sh ubuntu@${{ env.EC2_INSTANCE_IP }}:/tmp/deploy.sh
          ssh -T -i ~/.ssh/id_rsa ubuntu@${{ env.EC2_INSTANCE_IP }} "bash /tmp/deploy.sh"
          DEPLOY_EXIT=$?

          if [ $DEPLOY_EXIT -ne 0 ]; then
            echo "::error::Deployment failed with exit code $DEPLOY_EXIT"
            exit 1
          fi

          echo "‚úÖ Deployment successful"
        timeout-minutes: 25

      - name: Collect Performance Baseline
        run: |
          ssh -T -i ~/.ssh/id_rsa ubuntu@${{ env.EC2_INSTANCE_IP }} << 'ENDSSH'
            RESULTS_DIR="/tmp/benchmark-results/${{ matrix.config }}"
            mkdir -p "$RESULTS_DIR"
            
            if [ -x /opt/benchmark-tools/collect_metrics.sh ]; then
              /opt/benchmark-tools/collect_metrics.sh "${{ matrix.config }}" "$RESULTS_DIR"
            else
              echo "‚ö†Ô∏è  Metrics script not found, skipping"
            fi
          ENDSSH
        continue-on-error: true

      - name: Run Attack Suite
        run: |
          ssh -T -i ~/.ssh/id_rsa ubuntu@${{ env.EC2_INSTANCE_IP }} << 'ENDSSH'
            RESULTS_DIR="/tmp/benchmark-results/${{ matrix.config }}"
            
            if [ -x /opt/benchmark-tools/run_all_attacks.sh ]; then
              /opt/benchmark-tools/run_all_attacks.sh \
                "http://localhost:3000" \
                "${{ matrix.config }}" \
                "$RESULTS_DIR"
            else
              echo "‚ö†Ô∏è  Attack scripts not found, skipping"
            fi
          ENDSSH
        continue-on-error: true

      - name: Collect Security Logs
        run: |
          ssh -T -i ~/.ssh/id_rsa ubuntu@${{ env.EC2_INSTANCE_IP }} << 'ENDSSH'
            RESULTS_DIR="/tmp/benchmark-results/${{ matrix.config }}"
            
            docker logs juice-shop > "$RESULTS_DIR/container.log" 2>&1 || true
            
            grep -i "aikido\|datadog\|blocked\|detected\|attack" \
              "$RESULTS_DIR/container.log" > "$RESULTS_DIR/security_events.log" 2>&1 || true
            
            BLOCKED=$(grep -c "blocked" "$RESULTS_DIR/security_events.log" 2>/dev/null || echo "0")
            DETECTED=$(grep -c "detected" "$RESULTS_DIR/security_events.log" 2>/dev/null || echo "0")
            
            echo "METRIC,COUNT" > "$RESULTS_DIR/security_events.csv"
            echo "BLOCKED,$BLOCKED" >> "$RESULTS_DIR/security_events.csv"
            echo "DETECTED,$DETECTED" >> "$RESULTS_DIR/security_events.csv"
          ENDSSH

      - name: Download Results
        run: |
          mkdir -p ./results/${{ matrix.config }}
          scp -i ~/.ssh/id_rsa -r \
            ubuntu@${{ env.EC2_INSTANCE_IP }}:/tmp/benchmark-results/${{ matrix.config }}/* \
            ./results/${{ matrix.config }}/ || echo "No results to download"

      - name: Upload Results Artifact
        uses: actions/upload-artifact@v4
        with:
          name: results-${{ matrix.config }}
          path: ./results/${{ matrix.config }}/
          retention-days: 30
        continue-on-error: true

  comparative-analysis:
    name: üìà Generate Comparative Analysis
    runs-on: ubuntu-latest
    needs: benchmark-tests
    if: always()
    steps:
      - name: Checkout Code
        uses: actions/checkout@v4

      - name: Download All Results
        uses: actions/download-artifact@v4
        with:
          path: ./all-results
        continue-on-error: true

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install Analysis Tools
        run: pip install pandas matplotlib seaborn tabulate

      - name: Generate Analysis
        run: |
          python3 << 'PYEOF'
          import pandas as pd
          from pathlib import Path

          configs = ['baseline', 'iast-only', 'rasp-monitor', 'rasp-block']
          results_dir = Path('./all-results')

          if not results_dir.exists():
              print("‚ö†Ô∏è  No results found. Creating placeholder report.")
              with open('summary_statistics.csv', 'w') as f:
                  f.write('Configuration,Status\n')
                  f.write('ALL,NO_RESULTS\n')
              with open('comparative_results.csv', 'w') as f:
                  f.write('Configuration,Status\n')
                  f.write('ALL,NO_RESULTS\n')
              exit(0)

          all_data = []
          for config in configs:
              config_dir = results_dir / f'results-{config}' / config
              if not config_dir.exists():
                  continue
              
              summary_file = config_dir / 'summary.csv'
              if summary_file.exists():
                  try:
                      df = pd.read_csv(summary_file)
                      for _, row in df.iterrows():
                          if 'ATTACK_TYPE' in row and row.get('ATTACK_TYPE') == 'DURATION_SECONDS':
                              continue
                          all_data.append({
                              'Configuration': config,
                              'Attack Type': row.get('ATTACK_TYPE', 'UNKNOWN'),
                              'Total Attacks': row.get('TOTAL', 0),
                              'Detected': row.get('DETECTED', 0),
                              'Blocked': row.get('BLOCKED', 0),
                              'Detection Rate': f"{((row.get('DETECTED', 0) + row.get('BLOCKED', 0)) / max(row.get('TOTAL', 1), 1)) * 100:.1f}%",
                              'Block Rate': f"{(row.get('BLOCKED', 0) / max(row.get('TOTAL', 1), 1)) * 100:.1f}%"
                          })
                  except Exception as e:
                      print(f"Error reading {summary_file}: {e}")

          if len(all_data) == 0:
              print("‚ö†Ô∏è  No data collected")
              with open('summary_statistics.csv', 'w') as f:
                  f.write('Configuration,Status\n')
                  f.write('ALL,NO_DATA\n')
              with open('comparative_results.csv', 'w') as f:
                  f.write('Configuration,Status\n')
                  f.write('ALL,NO_DATA\n')
          else:
              df = pd.DataFrame(all_data)
              df.to_csv('comparative_results.csv', index=False)
              
              summary = []
              for config in configs:
                  config_data = df[df['Configuration'] == config]
                  if len(config_data) > 0:
                      total = config_data['Total Attacks'].sum()
                      detected = config_data['Detected'].sum()
                      blocked = config_data['Blocked'].sum()
                      summary.append({
                          'Configuration': config,
                          'Total Attacks': int(total),
                          'Total Detected': int(detected),
                          'Total Blocked': int(blocked),
                          'Detection Rate': f"{((detected + blocked) / total * 100):.1f}%" if total > 0 else "N/A",
                          'Block Rate': f"{(blocked / total * 100):.1f}%" if total > 0 else "N/A"
                      })
              
              if summary:
                  pd.DataFrame(summary).to_csv('summary_statistics.csv', index=False)
                  print("‚úÖ Analysis complete")
              else:
                  with open('summary_statistics.csv', 'w') as f:
                      f.write('Configuration,Status\n')
                      f.write('ALL,INSUFFICIENT_DATA\n')
          PYEOF

      - name: Generate Report
        run: |
          cat > BENCHMARK_REPORT.md << 'EOF'
          # üîí RASP vs IAST Comparative Benchmark Report

          **Pipeline Run:** #${{ github.run_number }}  
          **Date:** $(date '+%Y-%m-%d %H:%M:%S UTC')

          ## üìä Summary

          EOF

          if [ -f summary_statistics.csv ] && [ $(wc -l < summary_statistics.csv) -gt 1 ]; then
            python3 << 'PYEOF' >> BENCHMARK_REPORT.md || echo "_No data_" >> BENCHMARK_REPORT.md
          import pandas as pd
          try:
              df = pd.read_csv('summary_statistics.csv')
              if len(df) > 0:
                  print(df.to_markdown(index=False))
          except: pass
          PYEOF
          else
            echo "‚ö†Ô∏è  No benchmark results available" >> BENCHMARK_REPORT.md
          fi

          cat BENCHMARK_REPORT.md >> $GITHUB_STEP_SUMMARY

      - name: Upload Report
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-report
          path: |
            BENCHMARK_REPORT.md
            comparative_results.csv
            summary_statistics.csv
          retention-days: 90
        continue-on-error: true

  enhanced-dast-scan:
    name: üï∑Ô∏è OWASP ZAP DAST Scan
    runs-on: ubuntu-latest
    needs: [check-prerequisites, benchmark-tests]
    if: |
      always() &&
      needs.check-prerequisites.outputs.can_proceed == 'true' &&
      github.event_name != 'pull_request' &&
      (github.event.inputs.run_full_security_scan == 'true' || github.event.inputs.run_full_security_scan == '')
    steps:
      - name: Run ZAP Scan
        run: |
          docker run --rm \
            -v $(pwd):/zap/wrk/:rw \
            -t zaproxy/zap-stable \
            zap-baseline.py \
            -t http://${{ env.EC2_INSTANCE_IP }}:3000 \
            -r zap-report.html \
            -J zap-report.json \
            -w zap-report.md \
            -a -m 3 -T 120 \
            || echo "ZAP scan completed"
        continue-on-error: true
        timeout-minutes: 20

      - name: Upload ZAP Results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: zap-dast-results
          path: |
            zap-report.*
          retention-days: 30
        continue-on-error: true

  cleanup:
    name: üßπ Cleanup
    runs-on: ubuntu-latest
    needs: [benchmark-tests, comparative-analysis, enhanced-dast-scan]
    if: always()
    steps:
      - name: Setup SSH
        run: |
          mkdir -p ~/.ssh
          echo "${{ secrets.EC2_SSH_PRIVATE_KEY }}" > ~/.ssh/id_rsa
          chmod 600 ~/.ssh/id_rsa
          ssh-keyscan -H ${{ env.EC2_INSTANCE_IP }} >> ~/.ssh/known_hosts

      - name: Clean Up
        run: |
          ssh -T -i ~/.ssh/id_rsa ubuntu@${{ env.EC2_INSTANCE_IP }} << 'ENDSSH'
            rm -rf /tmp/benchmark-results /tmp/deploy.sh
            echo "‚úÖ Cleanup complete"
          ENDSSH
        continue-on-error: true
