name: RASP vs IAST Comparative Benchmarking Pipeline (FIXED)

on:
  push:
    branches: [main, dev, dev-test]
  pull_request:
    branches: [main, dev, dev-test]
  workflow_dispatch:
    inputs:
      skip_ansible:
        description: "Skip Ansible configuration"
        required: false
        type: boolean
        default: false
      test_configurations:
        description: "Test configurations to run"
        required: false
        type: choice
        default: "all"
        options:
          - all
          - baseline
          - iast-only
          - rasp-monitor
          - rasp-block
      include_zap_scan:
        description: "Include ZAP comprehensive scan (slower but thorough)"
        required: false
        type: boolean
        default: true
      zap_scan_depth:
        description: "ZAP scan depth"
        required: false
        type: choice
        default: "baseline"
        options:
          - baseline
          - full
      deploy_continuous:
        description: "Deploy continuous benchmark system"
        required: false
        type: boolean
        default: true
      enable_daily_reports:
        description: "Enable daily report generation"
        required: false
        type: boolean
        default: false

env:
  EC2_INSTANCE_IP: ${{ secrets.EC2_INSTANCE_IP }}
  SEMGREP_APP_TOKEN: ${{ secrets.SEMGREP_APP_TOKEN }}
  EC2_SSH_PRIVATE_KEY: ${{ secrets.EC2_SSH_PRIVATE_KEY }}
  ANSIBLE_VAULT_PASSWORD: ${{ secrets.ANSIBLE_VAULT_PASSWORD }}
  ZEN_FIREWALL_TOKEN: ${{ secrets.ZEN_FIREWALL_TOKEN }}

jobs:
  sast-semgrep:
    name: üîç SAST - Semgrep Security Scan
    runs-on: ubuntu-latest
    container:
      image: semgrep/semgrep
    steps:
      - name: Checkout Code
        uses: actions/checkout@v4

      - name: Run Semgrep Scan
        run: |
          semgrep scan --config=auto --json --output=semgrep-results.json || true
          semgrep scan --config=auto --sarif --output=semgrep-results.sarif || true
        env:
          SEMGREP_APP_TOKEN: ${{ secrets.SEMGREP_APP_TOKEN }}

      - name: Upload to Semgrep Dashboard
        if: always()
        run: semgrep ci
        env:
          SEMGREP_APP_TOKEN: ${{ secrets.SEMGREP_APP_TOKEN }}
        continue-on-error: true

      - name: Upload SARIF to GitHub Security
        if: always()
        uses: github/codeql-action/upload-sarif@v3
        with:
          sarif_file: semgrep-results.sarif
          category: semgrep
        continue-on-error: true

      - name: Upload Semgrep Artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: semgrep-results
          path: |
            semgrep-results.json
            semgrep-results.sarif

  check-prerequisites:
    name: ‚úÖ Verify Prerequisites
    runs-on: ubuntu-latest
    needs: sast-semgrep
    outputs:
      can_proceed: ${{ steps.check.outputs.can_proceed }}
    steps:
      - name: Check Required Secrets
        id: check
        run: |
          echo "Checking required secrets..."
          MISSING_SECRETS=()
          if [ -z "${{ secrets.EC2_INSTANCE_IP }}" ]; then
            MISSING_SECRETS+=("EC2_INSTANCE_IP")
          fi
          if [ -z "${{ secrets.EC2_SSH_PRIVATE_KEY }}" ]; then
            MISSING_SECRETS+=("EC2_SSH_PRIVATE_KEY")
          fi
          if [ -z "${{ secrets.ANSIBLE_VAULT_PASSWORD }}" ]; then
            MISSING_SECRETS+=("ANSIBLE_VAULT_PASSWORD")
          fi
          if [ -z "${{ secrets.ZEN_FIREWALL_TOKEN }}" ]; then
            MISSING_SECRETS+=("ZEN_FIREWALL_TOKEN")
          fi
          if [ ${#MISSING_SECRETS[@]} -ne 0 ]; then
            echo "::error::Missing required secrets: ${MISSING_SECRETS[*]}"
            echo "can_proceed=false" >> $GITHUB_OUTPUT
            exit 1
          fi
          echo "‚úÖ All required secrets are set"
          echo "can_proceed=true" >> $GITHUB_OUTPUT

  configure-instance:
    name: ‚öôÔ∏è Configure Instance with Ansible
    runs-on: ubuntu-latest
    needs: check-prerequisites
    if: |
      needs.check-prerequisites.outputs.can_proceed == 'true' &&
      github.event.inputs.skip_ansible != 'true'
    steps:
      - name: Checkout Code
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install Ansible
        run: pip install ansible boto3 botocore

      - name: Setup SSH Key
        run: |
          mkdir -p ~/.ssh
          echo "${{ secrets.EC2_SSH_PRIVATE_KEY }}" > ~/.ssh/id_rsa
          chmod 600 ~/.ssh/id_rsa

      - name: Configure SSH Keep-Alive
        run: |
          cat >> ~/.ssh/config << 'EOF'
          Host *
            ServerAliveInterval 30
            ServerAliveCountMax 10
            TCPKeepAlive yes
            ConnectTimeout 10
          EOF

      - name: Wait for SSH Availability
        run: |
          echo "Testing SSH connection..."
          for i in {1..30}; do
            if ssh -o StrictHostKeyChecking=no -o ConnectTimeout=5 \
               -i ~/.ssh/id_rsa ubuntu@${{ env.EC2_INSTANCE_IP }} \
               "echo 'SSH ready'" 2>/dev/null; then
              echo "‚úÖ SSH connection successful"
              exit 0
            fi
            echo "Attempt $i/30: Waiting for SSH..."
            sleep 10
          done
          echo "::error::SSH connection timeout"
          exit 1

      - name: Create Ansible Inventory
        run: |
          mkdir -p ansible
          cat > ansible/inventory.ini <<EOF
          [juiceshop]
          ${{ env.EC2_INSTANCE_IP }} ansible_user=ubuntu ansible_ssh_private_key_file=~/.ssh/id_rsa ansible_ssh_common_args='-o StrictHostKeyChecking=no'
          EOF

      - name: Create Vault Password File
        run: |
          cd ansible
          echo "${{ secrets.ANSIBLE_VAULT_PASSWORD }}" > .vault_pass
          chmod 600 .vault_pass

      - name: Run Ansible Playbook
        run: |
          cd ansible
          ansible-playbook -i inventory.ini playbook.yml \
            --vault-password-file .vault_pass -v
        timeout-minutes: 60

      - name: Clean Up Vault Password
        if: always()
        run: rm -f ansible/.vault_pass

  deploy-continuous-benchmark:
    name: üöÄ Deploy Continuous Benchmark System
    runs-on: ubuntu-latest
    needs: [check-prerequisites, configure-instance]
    if: |
      needs.check-prerequisites.outputs.can_proceed == 'true' &&
      (needs.configure-instance.result == 'success' || needs.configure-instance.result == 'skipped') &&
      (github.ref == 'refs/heads/main' || github.ref == 'refs/heads/dev-test' || github.event.inputs.deploy_continuous == 'true')
    steps:
      - name: Setup SSH Key
        run: |
          mkdir -p ~/.ssh
          echo "${{ secrets.EC2_SSH_PRIVATE_KEY }}" > ~/.ssh/id_rsa
          chmod 600 ~/.ssh/id_rsa
          ssh-keyscan -H ${{ env.EC2_INSTANCE_IP }} >> ~/.ssh/known_hosts

      - name: Configure SSH Keep-Alive
        run: |
          cat >> ~/.ssh/config << 'EOF'
          Host *
            ServerAliveInterval 30
            ServerAliveCountMax 10
            TCPKeepAlive yes
          EOF

      - name: Verify System Configuration
        run: |
          ssh -i ~/.ssh/id_rsa ubuntu@${{ env.EC2_INSTANCE_IP }} \
            'test -f /opt/benchmark-tools/start_benchmark_system.sh && echo "‚úÖ System configured" || exit 1'
        timeout-minutes: 1

      - name: Launch Continuous System (Background)
        run: |
          ssh -i ~/.ssh/id_rsa ubuntu@${{ env.EC2_INSTANCE_IP }} \
            'cd /opt/benchmark-tools && nohup ./start_benchmark_system.sh > /tmp/benchmark_startup.log 2>&1 & echo $! > /tmp/benchmark_startup.pid'

          echo "‚úÖ Startup script launched in background"
        timeout-minutes: 2

      - name: Wait for Initial Startup
        run: sleep 45

      - name: Check Deployment Status
        run: |
          ssh -i ~/.ssh/id_rsa ubuntu@${{ env.EC2_INSTANCE_IP }} << 'EOF'
            echo "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê"
            echo "Deployment Status Check"
            echo "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê"
            
            systemctl is-active continuous-benchmark && echo "‚úÖ Service: ACTIVE" || echo "‚è≥ Service: Starting"
            docker ps | grep -q prometheus && echo "‚úÖ Prometheus: UP" || echo "‚è≥ Prometheus: Starting"
            docker ps | grep -q grafana && echo "‚úÖ Grafana: UP" || echo "‚è≥ Grafana: Starting"
            
            echo ""
            echo "Startup log (last 15 lines):"
            tail -15 /tmp/benchmark_startup.log 2>/dev/null || echo "Log not yet available"
            
            echo ""
            echo "Note: Full deployment continues in background"
          EOF
        timeout-minutes: 1
        continue-on-error: true

      - name: Create Deployment Summary
        if: always()
        run: |
          PUBLIC_IP="${{ env.EC2_INSTANCE_IP }}"

          cat >> $GITHUB_STEP_SUMMARY << EOF
          # üöÄ Continuous Benchmark System Deployment

          ## üìä Access Points

          | Service | URL | Credentials |
          |---------|-----|-------------|
          | **Grafana Dashboard** | [http://${PUBLIC_IP}:3001](http://${PUBLIC_IP}:3001) | admin / rasp_vs_iast_2024 |
          | **Prometheus** | [http://${PUBLIC_IP}:9090](http://${PUBLIC_IP}:9090) | None required |
          | **Metrics Endpoint** | [http://${PUBLIC_IP}:8000/metrics](http://${PUBLIC_IP}:8000/metrics) | None required |

          ## ‚öôÔ∏è System Configuration

          - **Rotation Interval**: Each configuration runs for 60 minutes
          - **Attack Frequency**: Attacks execute every 5 minutes
          - **Data Retention**: 30 days

          ## üîß Management Commands

          \`\`\`bash
          # Check system status
          ssh ubuntu@${PUBLIC_IP} systemctl status continuous-benchmark

          # View logs
          ssh ubuntu@${PUBLIC_IP} journalctl -u continuous-benchmark -f

          # Check startup log
          ssh ubuntu@${PUBLIC_IP} tail -50 /tmp/benchmark_startup.log
          \`\`\`

          ‚è∞ **Status**: Deployed and initializing. Dashboards available in 5-10 minutes.
          EOF

  benchmark-tests:
    name: üß™ ${{ matrix.config_name }}
    runs-on: ubuntu-latest
    needs: [check-prerequisites, configure-instance]
    if: |
      needs.check-prerequisites.outputs.can_proceed == 'true' &&
      (needs.configure-instance.result == 'success' || needs.configure-instance.result == 'skipped') &&
      github.event.inputs.deploy_continuous != 'true'
    strategy:
      max-parallel: 1
      fail-fast: false
      matrix:
        include:
          - config: baseline
            config_name: "Configuration 1: Baseline (No Protection)"
            dd_appsec: "false"
            dd_iast: "false"
            aikido_block: "false"
            aikido_enabled: "false"
          - config: iast-only
            config_name: "Configuration 2: DataDog IAST Only"
            dd_appsec: "true"
            dd_iast: "true"
            aikido_block: "false"
            aikido_enabled: "false"
          - config: rasp-monitor
            config_name: "Configuration 3: Zen RASP (Monitoring)"
            dd_appsec: "false"
            dd_iast: "false"
            aikido_block: "false"
            aikido_enabled: "true"
          - config: rasp-block
            config_name: "Configuration 4: Zen RASP (Blocking)"
            dd_appsec: "false"
            dd_iast: "false"
            aikido_block: "true"
            aikido_enabled: "true"

    steps:
      - name: Checkout Code
        uses: actions/checkout@v4

      - name: Setup SSH Key
        run: |
          mkdir -p ~/.ssh
          echo "${{ secrets.EC2_SSH_PRIVATE_KEY }}" > ~/.ssh/id_rsa
          chmod 600 ~/.ssh/id_rsa
          ssh-keyscan -H ${{ env.EC2_INSTANCE_IP }} >> ~/.ssh/known_hosts

      - name: Configure SSH Keep-Alive
        run: |
          cat >> ~/.ssh/config << 'EOF'
          Host *
            ServerAliveInterval 30
            ServerAliveCountMax 10
            TCPKeepAlive yes
          EOF

      - name: Deploy Application with ${{ matrix.config }} Configuration
        run: |
          ssh -i ~/.ssh/id_rsa ubuntu@${{ env.EC2_INSTANCE_IP }} << 'ENDSSH'
            set -e
            cd /opt/juice-shop

            echo "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê"
            echo "üöÄ Deploying: ${{ matrix.config_name }}"
            echo "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê"

            docker compose down 2>/dev/null || true
            sleep 5

            cat > docker-compose.yml << 'COMPOSEEOF'
          services:
            juice-shop:
              image: juice-shop-secure:latest
              container_name: juice-shop
              restart: unless-stopped
              ports:
                - "3000:3000"
              environment:
                NODE_ENV: production
                DD_ENV: ${{ matrix.config }}
                DD_SERVICE: juice-shop
                DD_VERSION: latest
                DD_AGENT_HOST: 172.17.0.1
                DD_TRACE_AGENT_PORT: 8126
                DD_LOGS_INJECTION: "true"
                DD_TRACE_SAMPLE_RATE: "1"
                DD_PROFILING_ENABLED: "true"
                DD_RUNTIME_METRICS_ENABLED: "true"
                DD_APPSEC_ENABLED: "${{ matrix.dd_appsec }}"
                DD_IAST_ENABLED: "${{ matrix.dd_iast }}"
                AIKIDO_TOKEN: ${AIKIDO_TOKEN}
                AIKIDO_BLOCK: "${{ matrix.aikido_block }}"
                AIKIDO_DEBUG: "true"
                AIKIDO_ENABLED: "${{ matrix.aikido_enabled }}"
              env_file:
                - .env
              extra_hosts:
                - "host.docker.internal:host-gateway"
              healthcheck:
                test: ["CMD", "curl", "-f", "http://localhost:3000"]
                interval: 30s
                timeout: 10s
                retries: 3
                start_period: 60s
          COMPOSEEOF

            docker compose up -d

            echo "‚è≥ Waiting for application..."
            sleep 60

            for i in {1..10}; do
              if curl -f -s http://localhost:3000 > /dev/null; then
                echo "‚úÖ Application ready"
                echo ""
                echo "üìã Configuration:"
                echo "  - DataDog AppSec: ${{ matrix.dd_appsec }}"
                echo "  - DataDog IAST: ${{ matrix.dd_iast }}"
                echo "  - Aikido Enabled: ${{ matrix.aikido_enabled }}"
                echo "  - Aikido Blocking: ${{ matrix.aikido_block }}"
                exit 0
              fi
              echo "Waiting... ($i/10)"
              sleep 5
            done

            echo "‚ö†Ô∏è  Application may need more time, continuing anyway"
            exit 0
          ENDSSH
        timeout-minutes: 5

      - name: Run Custom Attack Suite
        run: |
          ssh -i ~/.ssh/id_rsa ubuntu@${{ env.EC2_INSTANCE_IP }} << 'ENDSSH'
            RESULTS_DIR="/tmp/benchmark-results/${{ matrix.config }}"
            mkdir -p "$RESULTS_DIR"
            
            if [ -x /opt/benchmark-tools/run_all_attacks.sh ]; then
              /opt/benchmark-tools/run_all_attacks.sh \
                "http://localhost:3000" \
                "${{ matrix.config }}" \
                "$RESULTS_DIR"
            else
              echo "‚ö†Ô∏è  Attack scripts not found"
            fi
          ENDSSH
        continue-on-error: true
        timeout-minutes: 10

      - name: Run ZAP Security Scan
        if: github.event.inputs.include_zap_scan == 'true'
        run: |
          ssh -i ~/.ssh/id_rsa ubuntu@${{ env.EC2_INSTANCE_IP }} << 'ENDSSH'
            RESULTS_DIR="/tmp/benchmark-results/${{ matrix.config }}"
            mkdir -p "$RESULTS_DIR"
            
            echo "üï∑Ô∏è  Running ZAP ${{ github.event.inputs.zap_scan_depth || 'baseline' }} scan..."
            
            SCAN_TYPE="${{ github.event.inputs.zap_scan_depth || 'baseline' }}"
            
            if [ "$SCAN_TYPE" = "baseline" ]; then
              TIMEOUT=300
              ZAP_CMD="zap-baseline.py"
            else
              TIMEOUT=1200
              ZAP_CMD="zap-full-scan.py"
            fi
            
            docker run --rm --network host \
              -v "$RESULTS_DIR:/zap/wrk:rw" \
              ghcr.io/zaproxy/zaproxy:stable \
              $ZAP_CMD \
              -t http://localhost:3000 \
              -r zap-report.html \
              -J zap-report.json \
              -w zap-report.md \
              -m 3 -T $TIMEOUT \
              || echo "ZAP scan completed with warnings"
            
            echo "‚úÖ ZAP scan completed"
          ENDSSH
        continue-on-error: true
        timeout-minutes: 25

      - name: Collect Security Logs
        run: |
          ssh -i ~/.ssh/id_rsa ubuntu@${{ env.EC2_INSTANCE_IP }} << 'ENDSSH'
            RESULTS_DIR="/tmp/benchmark-results/${{ matrix.config }}"
            
            docker logs juice-shop > "$RESULTS_DIR/container.log" 2>&1 || true
            
            grep -i "aikido\|datadog\|blocked\|detected\|attack" \
              "$RESULTS_DIR/container.log" > "$RESULTS_DIR/security_events.log" 2>&1 || true
            
            BLOCKED=$(grep -c "blocked" "$RESULTS_DIR/security_events.log" 2>/dev/null || echo "0")
            DETECTED=$(grep -c "detected" "$RESULTS_DIR/security_events.log" 2>/dev/null || echo "0")
            
            echo "METRIC,COUNT" > "$RESULTS_DIR/security_events.csv"
            echo "BLOCKED,$BLOCKED" >> "$RESULTS_DIR/security_events.csv"
            echo "DETECTED,$DETECTED" >> "$RESULTS_DIR/security_events.csv"
          ENDSSH
        timeout-minutes: 2

      - name: Download Results
        run: |
          mkdir -p ./results/${{ matrix.config }}
          scp -i ~/.ssh/id_rsa -r \
            ubuntu@${{ env.EC2_INSTANCE_IP }}:/tmp/benchmark-results/${{ matrix.config }}/* \
            ./results/${{ matrix.config }}/ || echo "No results to download"
        timeout-minutes: 5

      - name: Upload Results Artifact
        uses: actions/upload-artifact@v4
        with:
          name: results-${{ matrix.config }}
          path: ./results/${{ matrix.config }}/
          retention-days: 30
        continue-on-error: true

  comparative-analysis:
    name: üìà Generate Comprehensive Comparative Analysis
    runs-on: ubuntu-latest
    needs: benchmark-tests
    if: |
      always() &&
      needs.benchmark-tests.result != 'skipped'
    steps:
      - name: Checkout Code
        uses: actions/checkout@v4

      - name: Download All Results
        uses: actions/download-artifact@v4
        with:
          path: ./all-results
        continue-on-error: true

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install Analysis Tools
        run: pip install pandas matplotlib seaborn tabulate

      - name: Generate Comprehensive Analysis
        run: |
          python3 << 'PYEOF'
          import pandas as pd
          from pathlib import Path
          import json

          configs = ['baseline', 'iast-only', 'rasp-monitor', 'rasp-block']
          results_dir = Path('./all-results')

          if not results_dir.exists():
              print("‚ö†Ô∏è  No results found. Creating placeholder report.")
              with open('summary_statistics.csv', 'w') as f:
                  f.write('Configuration,Status\n')
                  f.write('ALL,NO_RESULTS\n')
              with open('comparative_results.csv', 'w') as f:
                  f.write('Configuration,Status\n')
                  f.write('ALL,NO_RESULTS\n')
              exit(0)

          all_data = []

          for config in configs:
              config_dir = results_dir / f'results-{config}' / config
              if not config_dir.exists():
                  continue
              
              summary_file = config_dir / 'summary.csv'
              if summary_file.exists():
                  try:
                      df = pd.read_csv(summary_file)
                      for _, row in df.iterrows():
                          if 'ATTACK_TYPE' in row and row.get('ATTACK_TYPE') == 'DURATION_SECONDS':
                              continue
                          all_data.append({
                              'Configuration': config,
                              'Source': 'Custom Scripts',
                              'Attack Type': row.get('ATTACK_TYPE', 'UNKNOWN'),
                              'Total Attacks': row.get('TOTAL', 0),
                              'Detected': row.get('DETECTED', 0),
                              'Blocked': row.get('BLOCKED', 0),
                              'Detection Rate': f"{((row.get('DETECTED', 0) + row.get('BLOCKED', 0)) / max(row.get('TOTAL', 1), 1)) * 100:.1f}%",
                              'Block Rate': f"{(row.get('BLOCKED', 0) / max(row.get('TOTAL', 1), 1)) * 100:.1f}%"
                          })
                  except Exception as e:
                      print(f"Error reading {summary_file}: {e}")
              
              zap_file = config_dir / 'zap-report.json'
              if zap_file.exists():
                  try:
                      with open(zap_file, 'r') as f:
                          zap_data = json.load(f)
                      
                      alerts = zap_data.get('site', [{}])[0].get('alerts', [])
                      high_risk = sum(1 for a in alerts if a.get('riskdesc', '').startswith('High'))
                      medium_risk = sum(1 for a in alerts if a.get('riskdesc', '').startswith('Medium'))
                      total_alerts = len(alerts)
                      
                      all_data.append({
                          'Configuration': config,
                          'Source': 'ZAP Scan',
                          'Attack Type': 'COMPREHENSIVE',
                          'Total Attacks': total_alerts,
                          'Detected': high_risk + medium_risk,
                          'Blocked': 0,
                          'Detection Rate': 'N/A',
                          'Block Rate': 'N/A'
                      })
                  except Exception as e:
                      print(f"Error reading ZAP results: {e}")

          if len(all_data) == 0:
              print("‚ö†Ô∏è  No data collected")
              with open('summary_statistics.csv', 'w') as f:
                  f.write('Configuration,Status\n')
                  f.write('ALL,NO_DATA\n')
              with open('comparative_results.csv', 'w') as f:
                  f.write('Configuration,Status\n')
                  f.write('ALL,NO_DATA\n')
          else:
              df = pd.DataFrame(all_data)
              df.to_csv('comparative_results.csv', index=False)
              
              summary = []
              for config in configs:
                  config_data = df[df['Configuration'] == config]
                  
                  if len(config_data) > 0:
                      custom_data = config_data[config_data['Source'] == 'Custom Scripts']
                      custom_total = custom_data['Total Attacks'].sum()
                      custom_detected = custom_data['Detected'].sum()
                      custom_blocked = custom_data['Blocked'].sum()
                      
                      zap_data = config_data[config_data['Source'] == 'ZAP Scan']
                      zap_total = zap_data['Total Attacks'].sum() if len(zap_data) > 0 else 0
                      zap_high = zap_data['Detected'].sum() if len(zap_data) > 0 else 0
                      
                      summary.append({
                          'Configuration': config,
                          'Custom Total': int(custom_total),
                          'Custom Blocked': int(custom_blocked),
                          'Custom Detection Rate': f"{((custom_detected + custom_blocked) / custom_total * 100):.1f}%" if custom_total > 0 else "N/A",
                          'ZAP Alerts': int(zap_total),
                          'ZAP High Risk': int(zap_high),
                          'Combined Score': f"{((custom_blocked / custom_total * 100) if custom_total > 0 else 0):.1f}%"
                      })
              
              if summary:
                  pd.DataFrame(summary).to_csv('summary_statistics.csv', index=False)
                  print("‚úÖ Analysis complete")
              else:
                  with open('summary_statistics.csv', 'w') as f:
                      f.write('Configuration,Status\n')
                      f.write('ALL,INSUFFICIENT_DATA\n')
          PYEOF

      - name: Generate Comprehensive Report
        run: |
          cat > BENCHMARK_REPORT.md << 'EOF'
          # üîí RASP vs IAST Comprehensive Benchmark Report

          **Pipeline Run:** #${{ github.run_number }}  
          **Date:** $(date '+%Y-%m-%d %H:%M:%S UTC')
          **Branch:** ${{ github.ref_name }}
          **Commit:** ${{ github.sha }}

          ## üìä Executive Summary

          This benchmark combines results from:
          1. **Custom Attack Scripts** - Focused, controlled attack testing
          2. **OWASP ZAP DAST** - Comprehensive automated security scanning
          3. **Continuous Monitoring** - 24/7 automated testing and metrics collection

          EOF

          if [ -f summary_statistics.csv ] && [ $(wc -l < summary_statistics.csv) -gt 1 ]; then
            python3 << 'PYEOF' >> BENCHMARK_REPORT.md || echo "_No data_" >> BENCHMARK_REPORT.md
          import pandas as pd
          try:
              df = pd.read_csv('summary_statistics.csv')
              if len(df) > 0:
                  print("\n## Configuration Comparison\n")
                  print(df.to_markdown(index=False))
                  
                  rasp = df[df['Configuration'] == 'rasp-block']
                  iast = df[df['Configuration'] == 'iast-only']
                  if len(rasp) > 0 and len(iast) > 0:
                      rasp_score = float(rasp['Combined Score'].values[0].strip('%'))
                      iast_score = float(iast['Combined Score'].values[0].strip('%'))
                      advantage = rasp_score - iast_score
                      print(f"\n### üèÜ Key Finding")
                      print(f"**Aikido RASP demonstrates {advantage:.1f}% better blocking effectiveness than DataDog IAST**")
          except: pass
          PYEOF
          else
            echo "‚ö†Ô∏è  No benchmark results available" >> BENCHMARK_REPORT.md
          fi

          cat BENCHMARK_REPORT.md >> $GITHUB_STEP_SUMMARY

      - name: Upload Comprehensive Report
        uses: actions/upload-artifact@v4
        with:
          name: comprehensive-benchmark-report
          path: |
            BENCHMARK_REPORT.md
            comparative_results.csv
            summary_statistics.csv
          retention-days: 90
        continue-on-error: true
